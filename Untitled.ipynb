{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMmX5tQwA8fThG6qsmGIscM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongDeokKo/GuKellyXiu_Replicate/blob/main/Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN_suT88ZFll"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nhOmFg2jBMg",
        "outputId": "2299e05b-f709-4990-f8f4-7e5084b02e06"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import multiprocessing as mp\n",
        "\n",
        "#추가함\n",
        "import math"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhTekCukPPIc",
        "outputId": "9f57c007-730d-4933-d837-1fae13eb9096"
      },
      "source": [
        "import torch\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "print(USE_CUDA)\n",
        "\n",
        "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
        "print('학습을 진행하는 기기:',device)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "학습을 진행하는 기기: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvQ-0tVXPVYn",
        "outputId": "eed366b2-3082-46ff-e347-5fed82832091"
      },
      "source": [
        "print('cuda index:', torch.cuda.current_device())\n",
        "\n",
        "print('gpu 개수:', torch.cuda.device_count())\n",
        "\n",
        "print('graphic name:', torch.cuda.get_device_name())\n",
        "\n",
        "cuda = torch.device('cuda')\n",
        "\n",
        "print(cuda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda index: 0\n",
            "gpu 개수: 1\n",
            "graphic name: Tesla P100-PCIE-16GB\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUhmpdtWPVcD"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-A-sCWEjB-F"
      },
      "source": [
        "\n",
        "\n",
        "#%% load data (interaction은 나중에 할때 부르고 지우는거 추가하자)\n",
        "new_firm_data = pd.read_csv('/content/drive/MyDrive/x_y_wo_inter.csv')\n",
        "\n",
        "new_firm_data[new_firm_data.columns[2:96]] = new_firm_data[new_firm_data.columns[2:96]].astype('float32')\n",
        "new_firm_data[new_firm_data.columns[0:2]] = new_firm_data[new_firm_data.columns[0:2]].astype('int32')\n",
        "new_firm_data[new_firm_data.columns[96:170]] = new_firm_data[new_firm_data.columns[96:170]].astype('int8')\n",
        "new_firm_data[new_firm_data.columns[170]] = new_firm_data[new_firm_data.columns[170]].astype('float32')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrTuyAlOjg-Z"
      },
      "source": [
        "#%% 1957.3 ~ 2016.12  > 1963.01 ~ 2016.12    \n",
        "# You can change 1963.01 with 'All_sample_Start'\n",
        "from datetime import datetime\n",
        "from dateutil import relativedelta\n",
        "\n",
        "\n",
        "date = new_firm_data['DATE']\n",
        "result = Counter(date)\n",
        "date_firm = list(result.keys())\n",
        "date_num_firm = list(result.values())\n",
        "\n",
        "del date\n",
        "del result \n",
        "\n",
        "# Gu,Kelly,Xiu sample period\n",
        "Gu_Start = '1957-03-31'   \n",
        "Gu_sample_End = '2016-12-31'     \n",
        "Gu_delta = relativedelta.relativedelta(datetime.strptime(Gu_sample_End, \"%Y-%m-%d\"), datetime.strptime(Gu_Start, \"%Y-%m-%d\"))\n",
        "Gu_sp_len = 12*Gu_delta.years + Gu_delta.months + 1  \n",
        "\n",
        "\n",
        "# Our All sample period\n",
        "All_sample_Start = '1963-01-31'  \n",
        "All_sample_End = Gu_sample_End       # final month is the same\n",
        "All_delta = relativedelta.relativedelta(datetime.strptime(All_sample_End, \"%Y-%m-%d\"), datetime.strptime(All_sample_Start, \"%Y-%m-%d\"))\n",
        "All_sp_len = 12*All_delta.years + All_delta.months + 1  \n",
        "\n",
        "delete_months = Gu_sp_len - All_sp_len\n",
        "\n",
        "date_firm = date_firm[delete_months:]\n",
        "date_num_firm = date_num_firm[delete_months:]\n",
        "new_firm_data = new_firm_data.iloc[-sum(date_num_firm):,:]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqpRuCNplKvn"
      },
      "source": [
        "#%%  Setting sample period\n",
        "# training : 17 years,  cv : 10 years, test : 27 years\n",
        "# training : 1963.1~1979.12, cv : 1980.1 ~ 1989.12, test : 1990.1 ~ 2016.12\n",
        "# after 1 year, we re-estimate our model with 1 more year training sample period  (CV last 10 year, 10 is fixed)\n",
        "\n",
        "# OOS period \n",
        "OOS_Start = '1990-01-31'  \n",
        "OOS_End = All_sample_End    \n",
        "OOS_delta = relativedelta.relativedelta(datetime.strptime(OOS_End, \"%Y-%m-%d\"), datetime.strptime(OOS_Start, \"%Y-%m-%d\"))\n",
        "OOS_len = 12*OOS_delta.years + OOS_delta.months + 1     \n",
        "OOS_num_estimate = math.ceil(OOS_len/12)    # = 27\n",
        "\n",
        "# CV\n",
        "CV_Start = '1980-01-31'  \n",
        "CV_End = '1989-12-31'    # 1month before OOS_End\n",
        "CV_delta = relativedelta.relativedelta(datetime.strptime(CV_End, \"%Y-%m-%d\"), datetime.strptime(CV_Start, \"%Y-%m-%d\"))\n",
        "CV_len = 12*CV_delta.years + CV_delta.months + 1   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ_fqk37gPh5"
      },
      "source": [
        "#%% To define Function\n",
        "\n",
        "def R2OOS(y_true, y_forecast):\n",
        "    \n",
        "    import numpy as np\n",
        "   \n",
        "    SSres = np.nansum(np.square(y_true-y_forecast))\n",
        "    SStot = np.nansum(np.square(y_true))\n",
        "\n",
        "    return 1-SSres/SStot\n",
        "\n",
        "\n",
        "# =========================================================================\n",
        "#   PCR, 94 + dummy variable(no intersection term), Use cross-validation to select the number of PCA components  \n",
        "# =========================================================================\n",
        "\n",
        "def Pca_regression(X, Y, numpc, num_tr_cv_te):\n",
        "    # numpc (list) : # of principal component ex[3,4,5,6,7]\n",
        "    # num_t_v (list) : # of training set & cross-val set   ex[100, 10]\n",
        "    # X consists of Traing, Val and Test set\n",
        "    \n",
        "    import numpy as np \n",
        "    from sklearn.decomposition import PCA\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    \n",
        "    num_train = num_tr_cv_te[0]\n",
        "    num_val = num_tr_cv_te[1]\n",
        "    num_test = num_tr_cv_te[2]\n",
        "    \n",
        "    # Split data into training and test\n",
        "    X_train = X[:num_train,:]\n",
        "    Y_train = Y[:num_train,:]\n",
        "    \n",
        "    X_val = X[num_train:(num_train+num_val),:]\n",
        "    Y_val = Y[num_train:(num_train+num_val),:]\n",
        "    \n",
        "    X_test = X[(num_train+num_val):,:]\n",
        "    \n",
        "       \n",
        "    # Scale Inputs for Training\n",
        "    X_scaler = StandardScaler()\n",
        "    X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "    \n",
        "    X_val_scaled = X_scaler.transform(X_val)\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "    \n",
        "    \n",
        "    # use cross-validation mean-squared-error to determine the number of principal component \n",
        "    mse = np.full((len(numpc),1),np.nan)\n",
        "\n",
        "    for i in range(len(numpc)):\n",
        "        pca = PCA(n_components = numpc[i])\n",
        "        principalComponents = pca.fit_transform(X_train_scaled)\n",
        "        \n",
        "        X_val_weighted = pca.transform(X_val_scaled)\n",
        "        \n",
        "        line_fitter = LinearRegression()\n",
        "        line_fitter.fit(principalComponents, Y_train)\n",
        "        \n",
        "        Ypred_val = np.full((num_val,1),np.nan)\n",
        "        for j in range(num_val):\n",
        "            Ypred_val[j,0] = line_fitter.predict(X_val_weighted[j,:].reshape(1,-1))\n",
        "                   \n",
        "        mse[i,0] = mean_squared_error(Y_val.reshape(-1), Ypred_val.reshape(-1))\n",
        "    \n",
        "    \n",
        "    argmin_numpc = numpc[np.argmin(mse)]\n",
        "    \n",
        "    # 위에 중에 했던거 한번 다시하는거긴 한데... 그냥하잠\n",
        "    pca = PCA(n_components = argmin_numpc)\n",
        "    principalComponents = pca.fit_transform(X_train_scaled)\n",
        "    \n",
        "    X_test_weighted = pca.transform(X_test_scaled)\n",
        "    \n",
        "    line_fitter = LinearRegression()\n",
        "    line_fitter.fit(principalComponents, Y_train)\n",
        "        \n",
        "    Ypred_test = np.full((num_test,1),np.nan)\n",
        "    for j in range(num_test):\n",
        "        Ypred_test[j,0]=line_fitter.predict(X_test_weighted[j,:].reshape(1,-1))\n",
        "        \n",
        "          \n",
        "    return Ypred_test, argmin_numpc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# =========================================================================\n",
        "#   PLS, 94 + dummy variable(no intersection term), Use cross-validation to select the number of components  \n",
        "# =========================================================================\n",
        "\n",
        "def Pls_regression(X,Y,numpls,num_tr_cv_te):\n",
        "    # numpls (list) : # of component ex[3,4,5,6,7]\n",
        "    # num_t_v (list) : # of training set & cross-val set   ex[100, 10]\n",
        "    # X consists of Traing, Val and Test set\n",
        "    \n",
        "    import numpy as np \n",
        "    from sklearn.cross_decomposition import PLSRegression\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    \n",
        "    num_train = num_tr_cv_te[0]\n",
        "    num_val = num_tr_cv_te[1]\n",
        "    num_test = num_tr_cv_te[2]\n",
        "    \n",
        "    # Split data into training and test\n",
        "    X_train = X[:num_train,:]\n",
        "    Y_train = Y[:num_train,:]\n",
        "    \n",
        "    X_val = X[num_train:(num_train+num_val),:]\n",
        "    Y_val = Y[num_train:(num_train+num_val),:]\n",
        "    \n",
        "    X_test = X[(num_train+num_val):,:]\n",
        "    \n",
        "       \n",
        "    # Scale Inputs for Training\n",
        "    X_scaler = StandardScaler()\n",
        "    X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "    \n",
        "    X_val_scaled = X_scaler.transform(X_val)\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "    \n",
        "    \n",
        "    # use cross-validation mean-squared-error to determine the number of component \n",
        "    mse = np.full((len(numpls),1),np.nan)\n",
        "\n",
        "    for i in range(len(numpls)):\n",
        "        pls = PLSRegression(n_components = numpls[i])\n",
        "        pls.fit(X_train_scaled, Y_train)\n",
        "                \n",
        "        Ypred_val = np.full((num_val,1),np.nan)\n",
        "        for j in range(num_val):\n",
        "            Ypred_val[j,0]=pls.predict(X_val_scaled[j,:].reshape(1,-1))          \n",
        "        \n",
        "        mse[i,0] = mean_squared_error(Y_val.reshape(-1), Ypred_val.reshape(-1))\n",
        "    \n",
        "    \n",
        "    argmin_numpls = numpls[np.argmin(mse)]\n",
        "    \n",
        "    pls = PLSRegression(n_components = argmin_numpls)\n",
        "    pls.fit(X_train_scaled, Y_train)\n",
        "                \n",
        "    Ypred_test = np.full((num_test,1),np.nan)\n",
        "    for j in range(num_test):\n",
        "        Ypred_test[j,0]=pls.predict(X_test_scaled[j,:].reshape(1,-1))          \n",
        "              \n",
        "    \n",
        "    return Ypred_test, argmin_numpls\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRHvwTxZLxob"
      },
      "source": [
        "# =========================================================================\n",
        "#  elastic-net, Loss : mse + penalty, 94 + dummy variable(no intersection term), hyperparameter tuning\n",
        "# ========================================================================= \n",
        "\n",
        "def elastic_net(X,Y,num_tr_cv_te):\n",
        "    # num_t_v (list) : # of training set & cross-val set   ex[100, 10]\n",
        "    # X consists of Traing, Val and Test set\n",
        "    \n",
        "    import numpy as np\n",
        "    from sklearn.linear_model import ElasticNetCV\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.model_selection import PredefinedSplit\n",
        "    \n",
        "    num_train = num_tr_cv_te[0]\n",
        "    num_val = num_tr_cv_te[1]\n",
        "    num_test = num_tr_cv_te[2]\n",
        "    \n",
        "    # Split data into training and test\n",
        "    X_train = X[:(num_train+num_val),:]   # train + validation\n",
        "    Y_train = Y[:(num_train+num_val),:]   # train + validation\n",
        "    \n",
        "    X_test = X[(num_train+num_val):,:]\n",
        "    \n",
        "       \n",
        "    # Scale Inputs for Training\n",
        "    X_scaler = StandardScaler()\n",
        "    X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "    \n",
        "    # pre-define validation \n",
        "    test_fold =  np.concatenate((np.full((num_train),-1),np.full((num_val),0)))\n",
        "    ps = PredefinedSplit(test_fold.tolist())\n",
        "    \n",
        "    # fit & predict \n",
        "    model = ElasticNetCV(cv=ps, max_iter=3000, n_jobs=-1, l1_ratio=[.01, .05, .1, .25, .5, .8, .95, 1], \\\n",
        "                         alphas = [.01, 0.05, 0.1, .25, .5, 1., 2., 3., 4.], random_state=42, selection ='random')\n",
        "    model = model.fit(X_train_scaled, Y_train.reshape(-1))\n",
        "    \n",
        "    Ypred_test = np.full((num_test,1),np.nan)\n",
        "    for j in range(num_test):\n",
        "        Ypred_test[j,0]=model.predict(X_test_scaled[j,:].reshape(1,-1))\n",
        "        \n",
        "    \n",
        "    return Ypred_test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# =========================================================================\n",
        "#   Generalized-linear, 94 + dummy variable(no intersection term), Use cross-validation to select the number of PCA components  \n",
        "# =========================================================================\n",
        "# Loss ftn : MSE (not huber loss)\n",
        "# We use Lasso (Not group Lass) \n",
        "# include spline series of order 2 \n",
        "# number of knots = [3,5,7...] and we choose the only one that minimize cross-validation MSE \n",
        "# we set knots by using linspace(col.mean-2*col.std, col.mean+2*col.std, # knots)\n",
        "# for example if we use 3 knots, the # of variables is 94(order1) + 94*3(order 2) + dummy(74) = 450 \n",
        "\n",
        "def general_linear(X,Y,num_tr_cv_te, num_knots):\n",
        "    # num_t_v (list) : # of training set & cross-val set   ex[100, 10]\n",
        "    # X consists of Traing, Val and Test set\n",
        "    \n",
        "    import numpy as np \n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.model_selection import PredefinedSplit\n",
        "    from sklearn.linear_model import LassoCV\n",
        "    \n",
        "    num_train = num_tr_cv_te[0]\n",
        "    num_val = num_tr_cv_te[1]\n",
        "    num_test = num_tr_cv_te[2]\n",
        "       \n",
        "    mse = np.full((len(num_knots),1),np.nan)\n",
        "    Ypred_test = np.full((len(num_knots),num_test,1),np.nan)\n",
        "    \n",
        "    for i in range(len(num_knots)):\n",
        "        \n",
        "        X_temp = X\n",
        "        \n",
        "        # 94 variables > make spline series of order 2\n",
        "        for j in range(94):\n",
        "            \n",
        "            # make knots\n",
        "            std_train = np.std(X[:num_train,j])\n",
        "            mean_train = np.mean(X[:num_train,j])           \n",
        "            \n",
        "            knots = np.linspace(mean_train-2*std_train, mean_train+2*std_train, num_knots[i])\n",
        "            \n",
        "            # add (variable - knots)**2 column\n",
        "            for k in knots:\n",
        "                add_col = ((X[:,j]-k)**2).reshape(-1,1)\n",
        "                X_temp = np.concatenate((X_temp, add_col), axis=1)\n",
        "        \n",
        "        print(X_temp.shape)\n",
        "        \n",
        "        # Split data into training and test\n",
        "        X_train = X_temp[:(num_train+num_val),:]   # train + validation\n",
        "        Y_train = Y[:(num_train+num_val),:]   # train + validation\n",
        "        \n",
        "        X_test = X_temp[(num_train+num_val):,:]\n",
        "        \n",
        "        # Scale Inputs for Training\n",
        "        X_scaler = StandardScaler()\n",
        "        X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "        \n",
        "        X_test_scaled = X_scaler.transform(X_test)\n",
        "        \n",
        "        # pre-define validation \n",
        "        test_fold =  np.concatenate((np.full((num_train),-1),np.full((num_val),0)))\n",
        "        ps = PredefinedSplit(test_fold.tolist())\n",
        "        \n",
        "        # we use cross-val to find best 'alpha'(penalty term in loss function)\n",
        "        model = LassoCV(cv=ps, max_iter=3000,  alphas = [.01, 0.05, 0.1, .25, .5, 1., 2., 3., 4.], \\\n",
        "                        n_jobs=-1, random_state=42)\n",
        "        model = model.fit(X_train_scaled, Y_train.reshape(-1))\n",
        "\n",
        "        \n",
        "        # to choose # of knots, calculate mse of validation set\n",
        "        Ypred_val = np.full((num_val,1),np.nan)\n",
        "        for j in range(num_val):\n",
        "            Ypred_val[j,0]=model.predict(X_train_scaled[num_train+j,:].reshape(1,-1))\n",
        "            \n",
        "        mse[i,0] = mean_squared_error(Y[num_train:(num_train+num_val),:].reshape(-1), Ypred_val.reshape(-1))\n",
        "        \n",
        "        # predict test set \n",
        "        for j in range(num_test):\n",
        "            Ypred_test[i,j,0]=model.predict(X_test_scaled[j,:].reshape(1,-1))\n",
        "    \n",
        "    \n",
        "    # choose knots that minimize mse in validation\n",
        "    argmin_index = np.argmin(mse)\n",
        "    \n",
        "    print(argmin_index)\n",
        "    \n",
        "    Ypred_test_final = Ypred_test[argmin_index,:,:].reshape(-1,1)\n",
        "    \n",
        "    return Ypred_test_final\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xsYNMlClyPx"
      },
      "source": [
        "#%% setting X, y\n",
        "\n",
        "X_no_inter = new_firm_data.iloc[:,2:-1]\n",
        "y = new_firm_data.iloc[:,-1] \n",
        "\n",
        "y_true = new_firm_data.iloc[-sum(date_num_firm[-OOS_len:]):,-1].to_numpy().reshape(-1,1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-KsmCRapwQf"
      },
      "source": [
        "#%% PCR \n",
        "# Use CV to determine the # of principal components \n",
        "\n",
        "for i in range(OOS_num_estimate): \n",
        "    print(i)\n",
        "    \n",
        "    num_train_months = All_sp_len-OOS_len-CV_len+12*i\n",
        "    num_cv_months = CV_len    #120 months\n",
        "    num_test_months = 12   # for each estimation, predict 12months\n",
        "    \n",
        "    num_train = sum(date_num_firm[:num_train_months])\n",
        "    num_cv = sum(date_num_firm[num_train_months:(num_train_months+num_cv_months)])\n",
        "    num_test = sum(date_num_firm[(num_train_months+num_cv_months):(num_train_months+num_cv_months+num_test_months)])\n",
        "    \n",
        "    num_tr_cv_te = [num_train, num_cv, num_test]\n",
        "    \n",
        "    # train + val + test \n",
        "    # split them in function 'Pca_regression' (num_train, num_cv, num_test is input variable) \n",
        "    X_all_pca = X_no_inter.iloc[:sum(num_tr_cv_te),:].to_numpy()    # train + val +test \n",
        "    y_all_pca = y.iloc[:sum(num_tr_cv_te)].to_numpy().reshape(-1,1)\n",
        "    \n",
        "    numpc = [3,5,10]\n",
        "    \n",
        "    # the 'best' number of principal component is different for each estimation     \n",
        "    Ypred_temp, argmin_numpc_temp = Pca_regression(X_all_pca, y_all_pca, numpc, num_tr_cv_te)\n",
        "    \n",
        "    if i==0:\n",
        "        Y_predict_pca = Ypred_temp\n",
        "        Y_predict_pca_numpc = [argmin_numpc_temp]\n",
        "    else:\n",
        "        Y_predict_pca = np.concatenate((Y_predict_pca, Ypred_temp), axis=0)\n",
        "        Y_predict_pca_numpc.append(argmin_numpc_temp)\n",
        "\n",
        "print('PCR')\n",
        "print(R2OOS(y_true, Y_predict_pca))\n",
        "\n",
        "Y_predict_pca = pd.DataFrame(Y_predict_pca, columns=['PCR'])\n",
        "Y_predict_pca = pd.concat([new_firm_data.iloc[-sum(date_num_firm[-OOS_len:]):,:2].reset_index(drop=True), Y_predict_pca.reset_index(drop=True)], axis=1)\n",
        "Y_predict_pca.to_csv('/content/drive/MyDrive/y_pcr.csv', index = False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2qrjh3GLv1A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UidACuLmhI7a"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrJxRolYhA07"
      },
      "source": [
        "#%% PLS \n",
        "# Use CV to determine the # of components \n",
        "\n",
        "for i in range(OOS_num_estimate): \n",
        "    print(i)\n",
        "    \n",
        "    num_train_months = All_sp_len-OOS_len-CV_len+12*i\n",
        "    num_cv_months = CV_len    #120 months\n",
        "    num_test_months = 12   # for each estimation, predict 12months\n",
        "    \n",
        "    num_train = sum(date_num_firm[:num_train_months])\n",
        "    num_cv = sum(date_num_firm[num_train_months:(num_train_months+num_cv_months)])\n",
        "    num_test = sum(date_num_firm[(num_train_months+num_cv_months):(num_train_months+num_cv_months+num_test_months)])\n",
        "    \n",
        "    num_tr_cv_te = [num_train, num_cv, num_test]\n",
        "    \n",
        "    # train + val + test \n",
        "    # split them in function 'Pls_regression' (num_train, num_cv, num_test is input variable) \n",
        "    X_all_pls = X_no_inter.iloc[:sum(num_tr_cv_te),:].to_numpy()    # no CV\n",
        "    y_all_pls = y.iloc[:sum(num_tr_cv_te)].to_numpy().reshape(-1,1)\n",
        "    \n",
        "    \n",
        "    numpls = [3,5,8,10]\n",
        "    \n",
        "    # the 'best' number of principal component is different for each estimation     \n",
        "    Ypred_temp, argmin_numpls_temp = Pls_regression(X_all_pls, y_all_pls, numpls, num_tr_cv_te)\n",
        "    \n",
        "    if i==0:\n",
        "        Y_predict_pls = Ypred_temp\n",
        "        Y_predict_pls_numpls = [argmin_numpls_temp]\n",
        "    else:\n",
        "        Y_predict_pls = np.concatenate((Y_predict_pls, Ypred_temp), axis=0)\n",
        "        Y_predict_pls_numpls.append(argmin_numpls_temp)\n",
        "\n",
        "\n",
        "print('PLS')\n",
        "print(R2OOS(y_true, Y_predict_pls))\n",
        "\n",
        "Y_predict_pls = pd.DataFrame(Y_predict_pls, columns=['PLS'])\n",
        "Y_predict_pls = pd.concat([new_firm_data.iloc[-sum(date_num_firm[-OOS_len:]):,:2].reset_index(drop=True), Y_predict_pls.reset_index(drop=True)], axis=1)\n",
        "Y_predict_pls.to_csv('/content/drive/MyDrive/y_pls.csv', index = False)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1yIpDVULzkc"
      },
      "source": [
        "\n",
        "def Neural_net(X, Y, num_tr_cv_te, archi, epoch, Seed):\n",
        "    # archi : # of neurons in hyden layer \n",
        "    # Use mini-batch, MSE Loss \n",
        "    # Linear > Relu > Batch-normalization > linear > Relu > BN .... > linear \n",
        "    # Adam optimizer, Learning decay, Early-stopping\n",
        "    \n",
        "    import torch \n",
        "    import torch.nn as nn\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    import numpy as np  \n",
        "    from torch.utils.data import TensorDataset\n",
        "    from torch.utils.data import DataLoader\n",
        "    \n",
        "    device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
        "\n",
        "    #seed \n",
        "    torch.manual_seed(Seed)\n",
        "    np.random.seed(Seed)\n",
        "    \n",
        "    num_train = num_tr_cv_te[0]\n",
        "    num_val = num_tr_cv_te[1]\n",
        "    num_test = num_tr_cv_te[2]\n",
        "    \n",
        "    # Split data into training and test\n",
        "    X_train = X[:num_train,:]\n",
        "    Y_train = Y[:num_train,:]\n",
        "    \n",
        "    X_val = X[num_train:(num_train+num_val),:]\n",
        "    Y_val = Y[num_train:(num_train+num_val),:]\n",
        "    \n",
        "    X_test = X[(num_train+num_val):,:]\n",
        "    \n",
        "       \n",
        "    # Scale Inputs for Training\n",
        "    X_scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "    X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "    \n",
        "    X_val_scaled = X_scaler.transform(X_val)\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "    \n",
        "    # from np.array > torch tensor \n",
        "    X_train_scaled = torch.tensor(X_train_scaled).to(device)    \n",
        "    X_val_scaled = torch.tensor(X_val_scaled).to(device)\n",
        "    X_test_scaled = torch.tensor(X_test_scaled).to(device)\n",
        "    \n",
        "    Y_train = torch.tensor(Y_train).to(device)\n",
        "    Y_val = torch.tensor(Y_val).to(device)\n",
        "        \n",
        "    # dataset\n",
        "    train_dataset = TensorDataset(X_train_scaled, Y_train)   \n",
        "    valid_dataset = TensorDataset(X_val_scaled, Y_val)\n",
        "    \n",
        "    trainloader = DataLoader(train_dataset, batch_size= 8192, shuffle=True, drop_last=True)\n",
        "    validloader = DataLoader(valid_dataset, batch_size= 8192, shuffle=True, drop_last=True)\n",
        "    \n",
        "\n",
        "\n",
        "    # define Network \n",
        "    class NN_fwd_model(nn.Module):\n",
        "        \n",
        "        def __init__(self, X_dim, Y_dim, archi):\n",
        "            \n",
        "            super(NN_fwd_model, self).__init__()\n",
        "            \n",
        "            n = len(archi)\n",
        "            self.nn_module = torch.nn.Sequential()\n",
        "            \n",
        "            for i in range(n):\n",
        "                if i==0:                 \n",
        "                    self.nn_module.add_module('linear'+str(i+1), nn.Linear(X_dim, archi[i]))\n",
        "                    self.nn_module.add_module('Relu'+str(i+1), nn.ReLU())\n",
        "                    self.nn_module.add_module('BN'+str(i+1), nn.BatchNorm1d(archi[i]))\n",
        "                    \n",
        "                else:                  \n",
        "                    self.nn_module.add_module('linear'+str(i+1), nn.Linear(archi[i-1], archi[i]))\n",
        "                    self.nn_module.add_module('Relu'+str(i+1), nn.ReLU())\n",
        "                    self.nn_module.add_module('BN'+str(i+1), nn.BatchNorm1d(archi[i]))                    \n",
        "            \n",
        "            # for output layer\n",
        "            self.lastlinear = nn.Linear(archi[-1], Y_dim)\n",
        "                    \n",
        "            # Using He-initilization \n",
        "            for m in self.nn_module:\n",
        "                if isinstance(m,nn.Linear):\n",
        "                    nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
        "            \n",
        "            nn.init.kaiming_normal_(self.lastlinear.weight, nonlinearity=\"relu\")\n",
        "                    \n",
        "         \n",
        "        def forward(self, X_train_scaled):\n",
        "           y_hat = self.nn_module(X_train_scaled)\n",
        "           y_hat = self.lastlinear(y_hat)\n",
        "           \n",
        "           return y_hat\n",
        "       \n",
        "        \n",
        "    model = NN_fwd_model(X_train_scaled.shape[1], Y_train.shape[1], archi)\n",
        "    model = model.to(device)\n",
        "    print(model)\n",
        "    \n",
        "    \n",
        "    # define loss ftn \n",
        "    loss_ftn = torch.nn.MSELoss()\n",
        "        \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr= 0.0075, weight_decay= 0.0005)\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
        "                                lr_lambda=lambda epoch: 0.975 ** epoch)\n",
        "    \n",
        "    min_val_loss = np.Inf\n",
        "    epochs_no_improve = np.nan\n",
        "\n",
        "    for i in range(epoch):       \n",
        "        \n",
        "        # to track the training loss as the model trains\n",
        "        train_losses = []\n",
        "        # to track the validation loss as the model trains\n",
        "        valid_losses = []\n",
        "        # to track the average training loss per epoch as the model trains\n",
        "        avg_train_losses = []\n",
        "        # to track the average validation loss per epoch as the model trains\n",
        "        avg_valid_losses = []\n",
        "  \n",
        "        model.train()\n",
        "        for (batch_X, batch_Y) in trainloader:\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "           \n",
        "            # compute the model output\n",
        "            trained_y = model(batch_X.float())            \n",
        "            \n",
        "            # calculate loss\n",
        "            \n",
        "            loss = loss_ftn(trained_y, batch_Y.float())        \n",
        "            # credit assignment\n",
        "            loss.backward()\n",
        "            \n",
        "            # update model weights\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            \n",
        "            train_losses.append(loss.item())\n",
        "        \n",
        "        model.eval()\n",
        "        for (batch_X_val, batch_Y_val) in validloader:\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(batch_X_val.float())\n",
        "            # calculate the loss\n",
        "            loss = loss_ftn(output, batch_Y_val.float())\n",
        "            # record validation loss\n",
        "            valid_losses.append(loss.item())         \n",
        "            \n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)        \n",
        "        \n",
        "        if i % 5 ==0:\n",
        "            print('the epoch number ' + str(i) + ' (train_loss) : ' + str(train_loss))\n",
        "            print('the epoch number ' + str(i) + ' (valid_loss) : ' + str(valid_loss))\n",
        "        \n",
        "        # Early-stopping\n",
        "        if valid_loss < min_val_loss:\n",
        "             epochs_no_improve = 0\n",
        "             min_val_loss = valid_loss\n",
        "             torch.save(model.state_dict(), 'best_model_NN.pt')\n",
        "  \n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            \n",
        "        if epochs_no_improve > 25:\n",
        "            print('Early stopping! at ' + str(i) + 'th Epochs' )\n",
        "            break\n",
        "        else:\n",
        "            continue\n",
        "        \n",
        "    \n",
        "    model.load_state_dict(torch.load('best_model_NN.pt'))\n",
        "    model.eval()\n",
        "    Ypred_test = np.full((num_test,1),np.nan)\n",
        "    for j in range(num_test):\n",
        "        Ypred_test[j,0]=model(X_test_scaled[j,:].float().unsqueeze(0))\n",
        "        \n",
        "        \n",
        "    return Ypred_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhN3F8p3ZO5f"
      },
      "source": [
        "archi3 = [32,16,8]\n",
        "epoch3 = 200\n",
        "\n",
        "archi2 = [32,16]\n",
        "epoch2 = 500\n",
        "\n",
        "seed1 = 1109\n",
        "seed2 = 1117\n",
        "seed3 = 1123"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XoZI_kS6YZw"
      },
      "source": [
        "# Temporary\n",
        "# OOS_num_estimate\n",
        "OOS_num_estimate_first = 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cSPLgDg8Yj4d",
        "outputId": "98eee3ab-6ab4-4fb2-91b3-ca6c9554a857"
      },
      "source": [
        "for i in range(OOS_num_estimate_first): \n",
        "    print(i)\n",
        "    \n",
        "    num_train_months = All_sp_len-OOS_len-CV_len+12*i\n",
        "    num_cv_months = CV_len    #120 months\n",
        "    num_test_months = 12   # for each estimation, predict 12months\n",
        "    \n",
        "    num_train = sum(date_num_firm[:num_train_months])\n",
        "    num_cv = sum(date_num_firm[num_train_months:(num_train_months+num_cv_months)])\n",
        "    num_test = sum(date_num_firm[(num_train_months+num_cv_months):(num_train_months+num_cv_months+num_test_months)])\n",
        "    \n",
        "    num_tr_cv_te = [num_train, num_cv, num_test]\n",
        "    \n",
        "    # train + val + test \n",
        "    # split them in function (num_train, num_cv, num_test is input variable) \n",
        "    X_all = X_no_inter.iloc[:sum(num_tr_cv_te),:].to_numpy()    # no CV\n",
        "    y_all = y.iloc[:sum(num_tr_cv_te)].to_numpy().reshape(-1,1)\n",
        "    \n",
        "     \n",
        "    Ypred_temp1 = Neural_net(X_all, y_all, num_tr_cv_te , archi3, epoch3, seed1)\n",
        "    Ypred_temp2 = Neural_net(X_all, y_all, num_tr_cv_te , archi3, epoch3, seed2)\n",
        "    Ypred_temp3 = Neural_net(X_all, y_all, num_tr_cv_te , archi3, epoch3, seed3)  \n",
        "\n",
        "    if i==0:\n",
        "        Y_predict_NN3_1 = Ypred_temp1\n",
        "        Y_predict_NN3_2 = Ypred_temp2\n",
        "        Y_predict_NN3_3 = Ypred_temp3\n",
        "    else:\n",
        "        Y_predict_NN3_1 = np.concatenate((Y_predict_NN3_1, Ypred_temp1), axis=0)\n",
        "        Y_predict_NN3_2 = np.concatenate((Y_predict_NN3_2, Ypred_temp2), axis=0)\n",
        "        Y_predict_NN3_3 = np.concatenate((Y_predict_NN3_3, Ypred_temp3), axis=0)\n",
        "\n",
        "Y_predict_NN3_1 = pd.DataFrame(Y_predict_NN3_1, columns=['NN3'])\n",
        "Y_predict_NN3_2 = pd.DataFrame(Y_predict_NN3_2, columns=['NN3'])\n",
        "Y_predict_NN3_3 = pd.DataFrame(Y_predict_NN3_3, columns=['NN3'])\n",
        "Y_predict_NN3_1.to_csv('/content/drive/MyDrive/y_NN3_1_1st.csv', index = False)\n",
        "Y_predict_NN3_2.to_csv('/content/drive/MyDrive/y_NN3_2_1st.csv', index = False)\n",
        "Y_predict_NN3_3.to_csv('/content/drive/MyDrive/y_NN3_3_1st.csv', index = False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.07252099369484258\n",
            "the epoch number 0 (valid_loss) : 2.1836822486736556\n",
            "the epoch number 5 (train_loss) : 0.02611828774931919\n",
            "the epoch number 5 (valid_loss) : 29.63174534927715\n",
            "the epoch number 10 (train_loss) : 0.02612112776701709\n",
            "the epoch number 10 (valid_loss) : 29.88895893096924\n",
            "the epoch number 15 (train_loss) : 0.02611125588237521\n",
            "the epoch number 15 (valid_loss) : 29.76319408416748\n",
            "the epoch number 20 (train_loss) : 0.026108973738120263\n",
            "the epoch number 20 (valid_loss) : 29.68118165839802\n",
            "the epoch number 25 (train_loss) : 0.026114951258143747\n",
            "the epoch number 25 (valid_loss) : 29.76307038827376\n",
            "Early stopping! at 26th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.12307617122150329\n",
            "the epoch number 0 (valid_loss) : 0.5806581913070246\n",
            "the epoch number 5 (train_loss) : 0.029306009883083493\n",
            "the epoch number 5 (valid_loss) : 7.27156218344515\n",
            "the epoch number 10 (train_loss) : 0.029294284531869084\n",
            "the epoch number 10 (valid_loss) : 7.263862127607519\n",
            "the epoch number 15 (train_loss) : 0.02929677091628672\n",
            "the epoch number 15 (valid_loss) : 7.154382310130379\n",
            "the epoch number 20 (train_loss) : 0.029303672106330652\n",
            "the epoch number 20 (valid_loss) : 7.092336974360726\n",
            "the epoch number 25 (train_loss) : 0.029306824150753308\n",
            "the epoch number 25 (valid_loss) : 7.2043817774816\n",
            "Early stopping! at 26th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.09789915118052299\n",
            "the epoch number 0 (valid_loss) : 0.6642549193718217\n",
            "the epoch number 5 (train_loss) : 0.029297601992645896\n",
            "the epoch number 5 (valid_loss) : 9.05496787483042\n",
            "the epoch number 10 (train_loss) : 0.02929841367954231\n",
            "the epoch number 10 (valid_loss) : 9.14959985559637\n",
            "the epoch number 15 (train_loss) : 0.02931062922061208\n",
            "the epoch number 15 (valid_loss) : 9.12471827864647\n",
            "the epoch number 20 (train_loss) : 0.029292003868753653\n",
            "the epoch number 20 (valid_loss) : 9.085486666722732\n",
            "the epoch number 25 (train_loss) : 0.029281964817320007\n",
            "the epoch number 25 (valid_loss) : 9.14764855666594\n",
            "Early stopping! at 26th Epochs\n",
            "1\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.0847586995197667\n",
            "the epoch number 0 (valid_loss) : 49.77205231984456\n",
            "the epoch number 5 (train_loss) : 0.02759065381768677\n",
            "the epoch number 5 (valid_loss) : 325.0224639892578\n",
            "the epoch number 10 (train_loss) : 0.02758390855871969\n",
            "the epoch number 10 (valid_loss) : 323.19512854682074\n",
            "the epoch number 15 (train_loss) : 0.027581126801669596\n",
            "the epoch number 15 (valid_loss) : 325.69884321424695\n",
            "the epoch number 20 (train_loss) : 0.027570276272793612\n",
            "the epoch number 20 (valid_loss) : 323.79802890353733\n",
            "the epoch number 25 (train_loss) : 0.027582927896744675\n",
            "the epoch number 25 (valid_loss) : 324.4627724541558\n",
            "Early stopping! at 26th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.10846393733388848\n",
            "the epoch number 0 (valid_loss) : 1.1154471420579486\n",
            "the epoch number 5 (train_loss) : 0.028884378034207556\n",
            "the epoch number 5 (valid_loss) : 5.150946590635511\n",
            "the epoch number 10 (train_loss) : 0.028887921902868482\n",
            "the epoch number 10 (valid_loss) : 5.13354643450843\n",
            "the epoch number 15 (train_loss) : 0.028884173784818914\n",
            "the epoch number 15 (valid_loss) : 5.179014197985331\n",
            "the epoch number 20 (train_loss) : 0.028888925123545857\n",
            "the epoch number 20 (valid_loss) : 5.14317835436927\n",
            "the epoch number 25 (train_loss) : 0.028892750831113923\n",
            "the epoch number 25 (valid_loss) : 5.001797159512837\n",
            "Early stopping! at 26th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.09582591350707743\n",
            "the epoch number 0 (valid_loss) : 3.800393213166131\n",
            "the epoch number 5 (train_loss) : 0.031242715898487303\n",
            "the epoch number 5 (valid_loss) : 41.433404784732396\n",
            "the epoch number 10 (train_loss) : 0.0312483800161216\n",
            "the epoch number 10 (valid_loss) : 41.35165916019016\n",
            "the epoch number 15 (train_loss) : 0.031269428444405396\n",
            "the epoch number 15 (valid_loss) : 41.25959479014079\n",
            "the epoch number 20 (train_loss) : 0.0312603156392773\n",
            "the epoch number 20 (valid_loss) : 40.018985970815024\n",
            "the epoch number 25 (train_loss) : 0.03125235651516252\n",
            "the epoch number 25 (valid_loss) : 42.19230003356934\n",
            "Early stopping! at 26th Epochs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-939216a6ad1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mY_predict_NN3_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYpred_temp3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mY_predict_NN3_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_predict_NN3_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYpred_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mY_predict_NN3_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_predict_NN3_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYpred_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mY_predict_NN3_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_predict_NN3_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYpred_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Ypred_temp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qjz2DlY5f6gC",
        "outputId": "a250592f-0194-49df-f588-582bfec0e370"
      },
      "source": [
        "Ypred_temp1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-4.79104035e-02],\n",
              "       [-2.48822093e-01],\n",
              "       [-4.53303568e-02],\n",
              "       ...,\n",
              "       [-2.92356476e+02],\n",
              "       [ 7.30318725e-02],\n",
              "       [-1.55918412e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQqe0higzkcc",
        "outputId": "9a043a1b-f4d5-4906-e6be-ee974bbfc10f"
      },
      "source": [
        "Ypred_temp2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -0.14516436],\n",
              "       [ -0.08842124],\n",
              "       [ -0.14166789],\n",
              "       ...,\n",
              "       [-20.54500961],\n",
              "       [ -0.03205432],\n",
              "       [ -0.13216096]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeU2dG1ozn1t",
        "outputId": "95e35d93-d5fd-4d13-db90-c98d8907f104"
      },
      "source": [
        "Ypred_temp3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-5.62425479e-02],\n",
              "       [-3.54958922e-01],\n",
              "       [-4.21324596e-02],\n",
              "       ...,\n",
              "       [ 8.18613663e+01],\n",
              "       [-3.60931069e-01],\n",
              "       [-2.17289835e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G2u_i3H111w",
        "outputId": "7b4a8eda-bd8d-439f-caa2-579377f47260"
      },
      "source": [
        "\n",
        "for i in range(6,13): \n",
        "    print(i)\n",
        "    \n",
        "    num_train_months = All_sp_len-OOS_len-CV_len+12*i\n",
        "    num_cv_months = CV_len    #120 months\n",
        "    num_test_months = 12   # for each estimation, predict 12months\n",
        "    \n",
        "    num_train = sum(date_num_firm[:num_train_months])\n",
        "    num_cv = sum(date_num_firm[num_train_months:(num_train_months+num_cv_months)])\n",
        "    num_test = sum(date_num_firm[(num_train_months+num_cv_months):(num_train_months+num_cv_months+num_test_months)])\n",
        "    \n",
        "    num_tr_cv_te = [num_train, num_cv, num_test]\n",
        "    \n",
        "    # train + val + test \n",
        "    # split them in function (num_train, num_cv, num_test is input variable) \n",
        "    X_all = X_no_inter.iloc[:sum(num_tr_cv_te),:].to_numpy()    # no CV\n",
        "    y_all = y.iloc[:sum(num_tr_cv_te)].to_numpy().reshape(-1,1)\n",
        "    \n",
        "    print('First Seed')\n",
        "    Ypred_temp1 = Neural_net(X_all, y_all, num_tr_cv_te , archi3, epoch3, seed1)\n",
        "    print('Second Seed')\n",
        "    Ypred_temp2 = Neural_net(X_all, y_all, num_tr_cv_te , archi3, epoch3, seed2)\n",
        "    print('Third Seed')\n",
        "    Ypred_temp3 = Neural_net(X_all, y_all, num_tr_cv_te , archi3, epoch3, seed3)  \n",
        "\n",
        "    if i==6:\n",
        "        Y_predict_NN3_1 = Ypred_temp1\n",
        "        Y_predict_NN3_2 = Ypred_temp2\n",
        "        Y_predict_NN3_3 = Ypred_temp3\n",
        "    else:\n",
        "        Y_predict_NN3_1 = np.concatenate((Y_predict_NN3_1, Ypred_temp1), axis=0)\n",
        "        Y_predict_NN3_2 = np.concatenate((Y_predict_NN3_2, Ypred_temp2), axis=0)\n",
        "        Y_predict_NN3_3 = np.concatenate((Y_predict_NN3_3, Ypred_temp3), axis=0)\n",
        "\n",
        "\n",
        "Y_predict_NN3_1 = pd.DataFrame(Y_predict_NN3_1, columns=['NN3'])\n",
        "Y_predict_NN3_2 = pd.DataFrame(Y_predict_NN3_2, columns=['NN3'])\n",
        "Y_predict_NN3_3 = pd.DataFrame(Y_predict_NN3_3, columns=['NN3'])\n",
        "Y_predict_NN3_1.to_csv('/content/drive/MyDrive/y_NN3_1_2nd.csv', index = False)\n",
        "Y_predict_NN3_2.to_csv('/content/drive/MyDrive/y_NN3_2_2nd.csv', index = False)\n",
        "Y_predict_NN3_3.to_csv('/content/drive/MyDrive/y_NN3_3_2nd.csv', index = False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.04835641557592472\n",
            "the epoch number 0 (valid_loss) : 0.07076970670445293\n",
            "the epoch number 5 (train_loss) : 0.026505860450272343\n",
            "the epoch number 5 (valid_loss) : 0.06939492108044672\n",
            "the epoch number 10 (train_loss) : 0.026506190294869073\n",
            "the epoch number 10 (valid_loss) : 0.06865255662477483\n",
            "the epoch number 15 (train_loss) : 0.026490286931054284\n",
            "the epoch number 15 (valid_loss) : 0.06852633053181219\n",
            "the epoch number 20 (train_loss) : 0.026505575024785885\n",
            "the epoch number 20 (valid_loss) : 0.06811889870932289\n",
            "the epoch number 25 (train_loss) : 0.026493836905210073\n",
            "the epoch number 25 (valid_loss) : 0.06881653039040518\n",
            "the epoch number 30 (train_loss) : 0.026514859642577535\n",
            "the epoch number 30 (valid_loss) : 0.06909617916772179\n",
            "Early stopping! at 34th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.06885833714072032\n",
            "the epoch number 0 (valid_loss) : 1.23452483647156\n",
            "the epoch number 5 (train_loss) : 0.027252412834809028\n",
            "the epoch number 5 (valid_loss) : 1.3668704089507753\n",
            "the epoch number 10 (train_loss) : 0.027248098834894086\n",
            "the epoch number 10 (valid_loss) : 1.3458068825523644\n",
            "the epoch number 15 (train_loss) : 0.027250265617293257\n",
            "the epoch number 15 (valid_loss) : 1.3551124609714629\n",
            "the epoch number 20 (train_loss) : 0.027247687275628096\n",
            "the epoch number 20 (valid_loss) : 1.332894447825703\n",
            "the epoch number 25 (train_loss) : 0.027245493619951582\n",
            "the epoch number 25 (valid_loss) : 1.3735446743667126\n",
            "Early stopping! at 26th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.06565001724956145\n",
            "the epoch number 0 (valid_loss) : 50.791495043455676\n",
            "the epoch number 5 (train_loss) : 0.029930094200122447\n",
            "the epoch number 5 (valid_loss) : 53.942073034086064\n",
            "the epoch number 10 (train_loss) : 0.029925359569433083\n",
            "the epoch number 10 (valid_loss) : 53.79350421175945\n",
            "the epoch number 15 (train_loss) : 0.029928794855834873\n",
            "the epoch number 15 (valid_loss) : 54.15371561276854\n",
            "the epoch number 20 (train_loss) : 0.029911769937922935\n",
            "the epoch number 20 (valid_loss) : 54.15638989805445\n",
            "the epoch number 25 (train_loss) : 0.029924373462341215\n",
            "the epoch number 25 (valid_loss) : 53.52514080805521\n",
            "the epoch number 30 (train_loss) : 0.029929939074484446\n",
            "the epoch number 30 (valid_loss) : 54.27488637226177\n",
            "Early stopping! at 34th Epochs\n",
            "7\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.048328099006139644\n",
            "the epoch number 0 (valid_loss) : 0.05163193409735302\n",
            "the epoch number 5 (train_loss) : 0.027226577215689295\n",
            "the epoch number 5 (valid_loss) : 0.05064893348739957\n",
            "the epoch number 10 (train_loss) : 0.027227881992011205\n",
            "the epoch number 10 (valid_loss) : 0.05068067267958848\n",
            "the epoch number 15 (train_loss) : 0.027230066068946047\n",
            "the epoch number 15 (valid_loss) : 0.0507526770234108\n",
            "the epoch number 20 (train_loss) : 0.027224259609554675\n",
            "the epoch number 20 (valid_loss) : 0.0507552066009562\n",
            "the epoch number 25 (train_loss) : 0.027225418095576003\n",
            "the epoch number 25 (valid_loss) : 0.050758087585838337\n",
            "the epoch number 30 (train_loss) : 0.027221874459415464\n",
            "the epoch number 30 (valid_loss) : 0.050792227305893625\n",
            "Early stopping! at 34th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.0655933010874065\n",
            "the epoch number 0 (valid_loss) : 0.6646050819599966\n",
            "the epoch number 5 (train_loss) : 0.027412579480743576\n",
            "the epoch number 5 (valid_loss) : 0.6321430854358763\n",
            "the epoch number 10 (train_loss) : 0.02741566835407247\n",
            "the epoch number 10 (valid_loss) : 0.6307635636965059\n",
            "the epoch number 15 (train_loss) : 0.02741164725987201\n",
            "the epoch number 15 (valid_loss) : 0.6298161686380517\n",
            "the epoch number 20 (train_loss) : 0.02741683246765999\n",
            "the epoch number 20 (valid_loss) : 0.6294889000929752\n",
            "the epoch number 25 (train_loss) : 0.027418585111063425\n",
            "the epoch number 25 (valid_loss) : 0.6277202724496711\n",
            "the epoch number 30 (train_loss) : 0.027415693902694587\n",
            "the epoch number 30 (valid_loss) : 0.6305887989067244\n",
            "the epoch number 35 (train_loss) : 0.02741354320805969\n",
            "the epoch number 35 (valid_loss) : 0.6325858473988637\n",
            "the epoch number 40 (train_loss) : 0.027412564936259116\n",
            "the epoch number 40 (valid_loss) : 0.6271757331659209\n",
            "the epoch number 45 (train_loss) : 0.027417571832102243\n",
            "the epoch number 45 (valid_loss) : 0.635991466214072\n",
            "the epoch number 50 (train_loss) : 0.027414776014943496\n",
            "the epoch number 50 (valid_loss) : 0.6247598392150875\n",
            "Early stopping! at 50th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.06471369101117688\n",
            "the epoch number 0 (valid_loss) : 5.153071505632603\n",
            "the epoch number 5 (train_loss) : 0.032277434839741555\n",
            "the epoch number 5 (valid_loss) : 5.044685021569988\n",
            "the epoch number 10 (train_loss) : 0.03227434113146143\n",
            "the epoch number 10 (valid_loss) : 5.04060808238837\n",
            "the epoch number 15 (train_loss) : 0.03227573271233139\n",
            "the epoch number 15 (valid_loss) : 5.070835922756848\n",
            "the epoch number 20 (train_loss) : 0.03227441491070369\n",
            "the epoch number 20 (valid_loss) : 5.081402594258763\n",
            "the epoch number 25 (train_loss) : 0.032274458663049316\n",
            "the epoch number 25 (valid_loss) : 5.048001042971352\n",
            "the epoch number 30 (train_loss) : 0.03226692890021818\n",
            "the epoch number 30 (valid_loss) : 5.049322531084126\n",
            "the epoch number 35 (train_loss) : 0.03227046326278372\n",
            "the epoch number 35 (valid_loss) : 5.055975654777491\n",
            "the epoch number 40 (train_loss) : 0.032278520114561345\n",
            "the epoch number 40 (valid_loss) : 5.042407884912671\n",
            "Early stopping! at 42th Epochs\n",
            "8\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.04571019583042489\n",
            "the epoch number 0 (valid_loss) : 0.04768961972189606\n",
            "the epoch number 5 (train_loss) : 0.027689096758401158\n",
            "the epoch number 5 (valid_loss) : 0.04715325307408604\n",
            "the epoch number 10 (train_loss) : 0.027693310061728718\n",
            "the epoch number 10 (valid_loss) : 0.04737176534232743\n",
            "the epoch number 15 (train_loss) : 0.027689181379233766\n",
            "the epoch number 15 (valid_loss) : 0.046428164415950074\n",
            "the epoch number 20 (train_loss) : 0.027686407419526025\n",
            "the epoch number 20 (valid_loss) : 0.047318135823951946\n",
            "the epoch number 25 (train_loss) : 0.027693543102074142\n",
            "the epoch number 25 (valid_loss) : 0.046827337747320126\n",
            "the epoch number 30 (train_loss) : 0.027688660146976938\n",
            "the epoch number 30 (valid_loss) : 0.047307814787560645\n",
            "the epoch number 35 (train_loss) : 0.02768945215356271\n",
            "the epoch number 35 (valid_loss) : 0.04726298252513649\n",
            "Early stopping! at 35th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.06753214062592447\n",
            "the epoch number 0 (valid_loss) : 1.0566254671355453\n",
            "the epoch number 5 (train_loss) : 0.029098738823702792\n",
            "the epoch number 5 (valid_loss) : 1.082095920116803\n",
            "the epoch number 10 (train_loss) : 0.029100727672312435\n",
            "the epoch number 10 (valid_loss) : 1.0844652619930581\n",
            "the epoch number 15 (train_loss) : 0.029100863744091515\n",
            "the epoch number 15 (valid_loss) : 1.0770914119864823\n",
            "the epoch number 20 (train_loss) : 0.02909834465838426\n",
            "the epoch number 20 (valid_loss) : 1.0704969507428483\n",
            "the epoch number 25 (train_loss) : 0.02909937021106679\n",
            "the epoch number 25 (valid_loss) : 1.0563724750499113\n",
            "the epoch number 30 (train_loss) : 0.02910070391433523\n",
            "the epoch number 30 (valid_loss) : 1.0680228744830014\n",
            "the epoch number 35 (train_loss) : 0.02909847941027572\n",
            "the epoch number 35 (valid_loss) : 1.078106461246626\n",
            "Early stopping! at 35th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.06186290146992696\n",
            "the epoch number 0 (valid_loss) : 23.00430110001236\n",
            "the epoch number 5 (train_loss) : 0.03197760897262997\n",
            "the epoch number 5 (valid_loss) : 23.163534056839595\n",
            "the epoch number 10 (train_loss) : 0.03196857247921015\n",
            "the epoch number 10 (valid_loss) : 23.240637827015252\n",
            "the epoch number 15 (train_loss) : 0.03197127168640396\n",
            "the epoch number 15 (valid_loss) : 23.203771376179173\n",
            "the epoch number 20 (train_loss) : 0.03197255909492243\n",
            "the epoch number 20 (valid_loss) : 23.35136409254249\n",
            "the epoch number 25 (train_loss) : 0.03197435094722059\n",
            "the epoch number 25 (valid_loss) : 23.11134665486736\n",
            "the epoch number 30 (train_loss) : 0.03197948490300321\n",
            "the epoch number 30 (valid_loss) : 23.180940119190772\n",
            "the epoch number 35 (train_loss) : 0.03197718213084123\n",
            "the epoch number 35 (valid_loss) : 23.110386827772636\n",
            "the epoch number 40 (train_loss) : 0.03197244087246475\n",
            "the epoch number 40 (valid_loss) : 23.35065281127981\n",
            "the epoch number 45 (train_loss) : 0.03196381878675215\n",
            "the epoch number 45 (valid_loss) : 23.055144072296695\n",
            "the epoch number 50 (train_loss) : 0.031969849007907294\n",
            "the epoch number 50 (valid_loss) : 23.17936566827494\n",
            "the epoch number 55 (train_loss) : 0.03197396933933757\n",
            "the epoch number 55 (valid_loss) : 23.138841320957066\n",
            "the epoch number 60 (train_loss) : 0.03196279879733427\n",
            "the epoch number 60 (valid_loss) : 23.060518003658416\n",
            "Early stopping! at 63th Epochs\n",
            "9\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.04553699963118719\n",
            "the epoch number 0 (valid_loss) : 0.04401127118113879\n",
            "the epoch number 5 (train_loss) : 0.028187236048697686\n",
            "the epoch number 5 (valid_loss) : 0.04372312460799475\n",
            "the epoch number 10 (train_loss) : 0.028178380281658647\n",
            "the epoch number 10 (valid_loss) : 0.04378385674040597\n",
            "the epoch number 15 (train_loss) : 0.028183173989842398\n",
            "the epoch number 15 (valid_loss) : 0.04375233484415321\n",
            "the epoch number 20 (train_loss) : 0.028179409664980372\n",
            "the epoch number 20 (valid_loss) : 0.04377264156937599\n",
            "the epoch number 25 (train_loss) : 0.02818561124366633\n",
            "the epoch number 25 (valid_loss) : 0.04363568788310429\n",
            "the epoch number 30 (train_loss) : 0.028180519107335843\n",
            "the epoch number 30 (valid_loss) : 0.043817146001635374\n",
            "the epoch number 35 (train_loss) : 0.02818510806338387\n",
            "the epoch number 35 (valid_loss) : 0.04379551310662751\n",
            "the epoch number 40 (train_loss) : 0.02817973190259119\n",
            "the epoch number 40 (valid_loss) : 0.04361208622251545\n",
            "Early stopping! at 44th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.06224599150906068\n",
            "the epoch number 0 (valid_loss) : 0.044861844195438934\n",
            "the epoch number 5 (train_loss) : 0.028876833594548776\n",
            "the epoch number 5 (valid_loss) : 0.04450190943237897\n",
            "the epoch number 10 (train_loss) : 0.028878229514042043\n",
            "the epoch number 10 (valid_loss) : 0.04452092237434946\n",
            "the epoch number 15 (train_loss) : 0.028879621060368437\n",
            "the epoch number 15 (valid_loss) : 0.04444856911494925\n",
            "the epoch number 20 (train_loss) : 0.028876810687484208\n",
            "the epoch number 20 (valid_loss) : 0.04432915818986592\n",
            "the epoch number 25 (train_loss) : 0.028873247482021403\n",
            "the epoch number 25 (valid_loss) : 0.044481610392665\n",
            "Early stopping! at 29th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.0588817507352518\n",
            "the epoch number 0 (valid_loss) : 0.04898751043790096\n",
            "the epoch number 5 (train_loss) : 0.031117589450123148\n",
            "the epoch number 5 (valid_loss) : 0.048610102385282516\n",
            "the epoch number 10 (train_loss) : 0.03109989528145109\n",
            "the epoch number 10 (valid_loss) : 0.048565791936608045\n",
            "the epoch number 15 (train_loss) : 0.031111153814455738\n",
            "the epoch number 15 (valid_loss) : 0.04859045574122721\n",
            "the epoch number 20 (train_loss) : 0.031099157118649218\n",
            "the epoch number 20 (valid_loss) : 0.04853577844731442\n",
            "the epoch number 25 (train_loss) : 0.031113200745782495\n",
            "the epoch number 25 (valid_loss) : 0.048600896723098586\n",
            "the epoch number 30 (train_loss) : 0.03112534804975394\n",
            "the epoch number 30 (valid_loss) : 0.048475570473316555\n",
            "the epoch number 35 (train_loss) : 0.03111769987837128\n",
            "the epoch number 35 (valid_loss) : 0.048587611968721356\n",
            "the epoch number 40 (train_loss) : 0.031119873180337574\n",
            "the epoch number 40 (valid_loss) : 0.0485686048999563\n",
            "the epoch number 45 (train_loss) : 0.031115275443248127\n",
            "the epoch number 45 (valid_loss) : 0.048537546517075716\n",
            "the epoch number 50 (train_loss) : 0.03112724982202053\n",
            "the epoch number 50 (valid_loss) : 0.04856874542059125\n",
            "the epoch number 55 (train_loss) : 0.031115185608219655\n",
            "the epoch number 55 (valid_loss) : 0.04856428309335365\n",
            "the epoch number 60 (train_loss) : 0.031111350977180166\n",
            "the epoch number 60 (valid_loss) : 0.04860305829762338\n",
            "the epoch number 65 (train_loss) : 0.031113514688259326\n",
            "the epoch number 65 (valid_loss) : 0.048519193958323284\n",
            "Early stopping! at 69th Epochs\n",
            "10\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.04415972470932188\n",
            "the epoch number 0 (valid_loss) : 0.046641995607499494\n",
            "the epoch number 5 (train_loss) : 0.02828167943142311\n",
            "the epoch number 5 (valid_loss) : 0.04647135832592061\n",
            "the epoch number 10 (train_loss) : 0.028285398512904406\n",
            "the epoch number 10 (valid_loss) : 0.04641863517463207\n",
            "the epoch number 15 (train_loss) : 0.028289223721588565\n",
            "the epoch number 15 (valid_loss) : 0.04647083838650009\n",
            "the epoch number 20 (train_loss) : 0.028283134004787394\n",
            "the epoch number 20 (valid_loss) : 0.046468548672763926\n",
            "the epoch number 25 (train_loss) : 0.028290222306349123\n",
            "the epoch number 25 (valid_loss) : 0.046483945264889484\n",
            "Early stopping! at 28th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.06288245913970192\n",
            "the epoch number 0 (valid_loss) : 0.04749982683151437\n",
            "the epoch number 5 (train_loss) : 0.029691963244164198\n",
            "the epoch number 5 (valid_loss) : 0.047203274084287775\n",
            "the epoch number 10 (train_loss) : 0.029688795255115856\n",
            "the epoch number 10 (valid_loss) : 0.0471891318366193\n",
            "the epoch number 15 (train_loss) : 0.029697493426719603\n",
            "the epoch number 15 (valid_loss) : 0.047134566300532275\n",
            "the epoch number 20 (train_loss) : 0.029701799459276142\n",
            "the epoch number 20 (valid_loss) : 0.047170762560869516\n",
            "the epoch number 25 (train_loss) : 0.029691204679204008\n",
            "the epoch number 25 (valid_loss) : 0.0472118966281414\n",
            "the epoch number 30 (train_loss) : 0.029702491306683475\n",
            "the epoch number 30 (valid_loss) : 0.047145349447403034\n",
            "the epoch number 35 (train_loss) : 0.029699045042806897\n",
            "the epoch number 35 (valid_loss) : 0.04722759006708337\n",
            "the epoch number 40 (train_loss) : 0.029699215109933886\n",
            "the epoch number 40 (valid_loss) : 0.0469983889672317\n",
            "the epoch number 45 (train_loss) : 0.029695008265954708\n",
            "the epoch number 45 (valid_loss) : 0.04715898368311556\n",
            "the epoch number 50 (train_loss) : 0.029699819162487984\n",
            "the epoch number 50 (valid_loss) : 0.04720351001934001\n",
            "the epoch number 55 (train_loss) : 0.029697956059846962\n",
            "the epoch number 55 (valid_loss) : 0.0471707647829725\n",
            "the epoch number 60 (train_loss) : 0.029693931286707956\n",
            "the epoch number 60 (valid_loss) : 0.04716079584077785\n",
            "the epoch number 65 (train_loss) : 0.029695982560079697\n",
            "the epoch number 65 (valid_loss) : 0.047259901633910965\n",
            "Early stopping! at 66th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.05707983658458406\n",
            "the epoch number 0 (valid_loss) : 0.052162430102103634\n",
            "the epoch number 5 (train_loss) : 0.03125949606996531\n",
            "the epoch number 5 (valid_loss) : 0.05185585018051298\n",
            "the epoch number 10 (train_loss) : 0.03125644384812542\n",
            "the epoch number 10 (valid_loss) : 0.051935411466841115\n",
            "the epoch number 15 (train_loss) : 0.03125355504888889\n",
            "the epoch number 15 (valid_loss) : 0.05181700628446905\n",
            "the epoch number 20 (train_loss) : 0.031251215991395256\n",
            "the epoch number 20 (valid_loss) : 0.051838599798972144\n",
            "the epoch number 25 (train_loss) : 0.031257085262509116\n",
            "the epoch number 25 (valid_loss) : 0.05189979367219565\n",
            "the epoch number 30 (train_loss) : 0.03125721516839245\n",
            "the epoch number 30 (valid_loss) : 0.05183848170073409\n",
            "the epoch number 35 (train_loss) : 0.03124048226453059\n",
            "the epoch number 35 (valid_loss) : 0.05193175506173519\n",
            "Early stopping! at 39th Epochs\n",
            "11\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.046816800710641676\n",
            "the epoch number 0 (valid_loss) : 0.05149663737493342\n",
            "the epoch number 5 (train_loss) : 0.029612227477547194\n",
            "the epoch number 5 (valid_loss) : 0.05127269562719197\n",
            "the epoch number 10 (train_loss) : 0.029617069454656707\n",
            "the epoch number 10 (valid_loss) : 0.051257238145275365\n",
            "the epoch number 15 (train_loss) : 0.029616895442207653\n",
            "the epoch number 15 (valid_loss) : 0.05124068324422014\n",
            "the epoch number 20 (train_loss) : 0.029594331917663416\n",
            "the epoch number 20 (valid_loss) : 0.05124938484795134\n",
            "the epoch number 25 (train_loss) : 0.02959887024222149\n",
            "the epoch number 25 (valid_loss) : 0.05124222403713342\n",
            "the epoch number 30 (train_loss) : 0.029612879993187055\n",
            "the epoch number 30 (valid_loss) : 0.05122799673599416\n",
            "the epoch number 35 (train_loss) : 0.02962691717677646\n",
            "the epoch number 35 (valid_loss) : 0.051234532372447954\n",
            "the epoch number 40 (train_loss) : 0.029620845512383514\n",
            "the epoch number 40 (valid_loss) : 0.05122612269017203\n",
            "the epoch number 45 (train_loss) : 0.02961764234221644\n",
            "the epoch number 45 (valid_loss) : 0.05126904712283406\n",
            "Early stopping! at 47th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.0599153035113381\n",
            "the epoch number 0 (valid_loss) : 0.05046245147441995\n",
            "the epoch number 5 (train_loss) : 0.030027024654878512\n",
            "the epoch number 5 (valid_loss) : 0.050213235687336016\n",
            "the epoch number 10 (train_loss) : 0.03003846714273095\n",
            "the epoch number 10 (valid_loss) : 0.050285689725444234\n",
            "the epoch number 15 (train_loss) : 0.030041505251493718\n",
            "the epoch number 15 (valid_loss) : 0.050205736902767216\n",
            "the epoch number 20 (train_loss) : 0.03003286969744497\n",
            "the epoch number 20 (valid_loss) : 0.05022915969763336\n",
            "the epoch number 25 (train_loss) : 0.03003592701214883\n",
            "the epoch number 25 (valid_loss) : 0.050273889450934424\n",
            "the epoch number 30 (train_loss) : 0.03003051604868637\n",
            "the epoch number 30 (valid_loss) : 0.05028430558741093\n",
            "the epoch number 35 (train_loss) : 0.030042686437567075\n",
            "the epoch number 35 (valid_loss) : 0.05016203404500567\n",
            "the epoch number 40 (train_loss) : 0.03003332004364994\n",
            "the epoch number 40 (valid_loss) : 0.05025219531922505\n",
            "the epoch number 45 (train_loss) : 0.030026334710419177\n",
            "the epoch number 45 (valid_loss) : 0.05025487630788622\n",
            "the epoch number 50 (train_loss) : 0.03003290609146158\n",
            "the epoch number 50 (valid_loss) : 0.050284002233168174\n",
            "the epoch number 55 (train_loss) : 0.030043245883037646\n",
            "the epoch number 55 (valid_loss) : 0.05021736430453843\n",
            "Early stopping! at 58th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.05832218883766068\n",
            "the epoch number 0 (valid_loss) : 0.05585436298158662\n",
            "the epoch number 5 (train_loss) : 0.03271578611392114\n",
            "the epoch number 5 (valid_loss) : 0.055574356032342745\n",
            "the epoch number 10 (train_loss) : 0.03273019899303715\n",
            "the epoch number 10 (valid_loss) : 0.05561997433160913\n",
            "the epoch number 15 (train_loss) : 0.032686374771098294\n",
            "the epoch number 15 (valid_loss) : 0.05557739519482029\n",
            "the epoch number 20 (train_loss) : 0.03271406018692586\n",
            "the epoch number 20 (valid_loss) : 0.05558395674773332\n",
            "the epoch number 25 (train_loss) : 0.032698583664993446\n",
            "the epoch number 25 (valid_loss) : 0.055669004836216056\n",
            "the epoch number 30 (train_loss) : 0.032722599090387425\n",
            "the epoch number 30 (valid_loss) : 0.05559423829204049\n",
            "Early stopping! at 34th Epochs\n",
            "12\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.04494102762914018\n",
            "the epoch number 0 (valid_loss) : 0.04822003971944507\n",
            "the epoch number 5 (train_loss) : 0.031405207671617204\n",
            "the epoch number 5 (valid_loss) : 0.048090143654591\n",
            "the epoch number 10 (train_loss) : 0.031413418407502926\n",
            "the epoch number 10 (valid_loss) : 0.0481439612678483\n",
            "the epoch number 15 (train_loss) : 0.03140832572979362\n",
            "the epoch number 15 (valid_loss) : 0.047993815830375396\n",
            "the epoch number 20 (train_loss) : 0.031426663922244\n",
            "the epoch number 20 (valid_loss) : 0.04811946398172623\n",
            "the epoch number 25 (train_loss) : 0.03141881654921331\n",
            "the epoch number 25 (valid_loss) : 0.04809206230645506\n",
            "the epoch number 30 (train_loss) : 0.031419956939000834\n",
            "the epoch number 30 (valid_loss) : 0.04809628621253193\n",
            "the epoch number 35 (train_loss) : 0.031386463177439414\n",
            "the epoch number 35 (valid_loss) : 0.048116126949461095\n",
            "Early stopping! at 37th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.06140262324755129\n",
            "the epoch number 0 (valid_loss) : 0.04814838439735592\n",
            "the epoch number 5 (train_loss) : 0.03197931089487515\n",
            "the epoch number 5 (valid_loss) : 0.048135156623828106\n",
            "the epoch number 10 (train_loss) : 0.031958263043902424\n",
            "the epoch number 10 (valid_loss) : 0.04809702846866388\n",
            "the epoch number 15 (train_loss) : 0.03198424776721942\n",
            "the epoch number 15 (valid_loss) : 0.047739705150453456\n",
            "the epoch number 20 (train_loss) : 0.031966091800285014\n",
            "the epoch number 20 (valid_loss) : 0.04803810708033733\n",
            "the epoch number 25 (train_loss) : 0.03196553610461323\n",
            "the epoch number 25 (valid_loss) : 0.04807748699672202\n",
            "the epoch number 30 (train_loss) : 0.03196919379069617\n",
            "the epoch number 30 (valid_loss) : 0.04813930026104308\n",
            "the epoch number 35 (train_loss) : 0.03197717674468693\n",
            "the epoch number 35 (valid_loss) : 0.04809320867698417\n",
            "the epoch number 40 (train_loss) : 0.031970998752666145\n",
            "the epoch number 40 (valid_loss) : 0.048148247262096815\n",
            "Early stopping! at 41th Epochs\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.05790576556403386\n",
            "the epoch number 0 (valid_loss) : 0.05390524982005103\n",
            "the epoch number 5 (train_loss) : 0.034348073807594026\n",
            "the epoch number 5 (valid_loss) : 0.05366078496743471\n",
            "the epoch number 10 (train_loss) : 0.03435071969502851\n",
            "the epoch number 10 (valid_loss) : 0.053698928342161015\n",
            "the epoch number 15 (train_loss) : 0.034373108689722265\n",
            "the epoch number 15 (valid_loss) : 0.053828193623031304\n",
            "the epoch number 20 (train_loss) : 0.03436850018211101\n",
            "the epoch number 20 (valid_loss) : 0.05377422776232418\n",
            "the epoch number 25 (train_loss) : 0.034353968540304584\n",
            "the epoch number 25 (valid_loss) : 0.053743641632489667\n",
            "the epoch number 30 (train_loss) : 0.034355951120194635\n",
            "the epoch number 30 (valid_loss) : 0.05370113224937366\n",
            "the epoch number 35 (train_loss) : 0.03436388037118473\n",
            "the epoch number 35 (valid_loss) : 0.05384580491699724\n",
            "the epoch number 40 (train_loss) : 0.03436082328032506\n",
            "the epoch number 40 (valid_loss) : 0.053591394239765965\n",
            "the epoch number 45 (train_loss) : 0.034354295522758836\n",
            "the epoch number 45 (valid_loss) : 0.0537740746115008\n",
            "the epoch number 50 (train_loss) : 0.034372416138648984\n",
            "the epoch number 50 (valid_loss) : 0.053710626772581004\n",
            "Early stopping! at 54th Epochs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AWsRn_5b9Gn",
        "outputId": "c28d1a7a-6efc-47d9-985e-c98bb0babd64"
      },
      "source": [
        "\n",
        "for i in range(13,15): \n",
        "    print(i)\n",
        "    \n",
        "    num_train_months = All_sp_len-OOS_len-CV_len+12*i\n",
        "    num_cv_months = CV_len    #120 months\n",
        "    num_test_months = 12   # for each estimation, predict 12months\n",
        "    \n",
        "    num_train = sum(date_num_firm[:num_train_months])\n",
        "    num_cv = sum(date_num_firm[num_train_months:(num_train_months+num_cv_months)])\n",
        "    num_test = sum(date_num_firm[(num_train_months+num_cv_months):(num_train_months+num_cv_months+num_test_months)])\n",
        "    \n",
        "    num_tr_cv_te = [num_train, num_cv, num_test]\n",
        "    \n",
        "    # train + val + test \n",
        "    # split them in function (num_train, num_cv, num_test is input variable) \n",
        "    X_all = X_no_inter.iloc[:sum(num_tr_cv_te),:].to_numpy()    # no CV\n",
        "    y_all = y.iloc[:sum(num_tr_cv_te)].to_numpy().reshape(-1,1)\n",
        "    \n",
        "    print('First Seed')\n",
        "    Ypred_temp1 = Neural_net(X_all, y_all, num_tr_cv_te , archi3, epoch3, seed1)\n",
        "    print('Second Seed')\n",
        "    Ypred_temp2 = Neural_net(X_all, y_all, num_tr_cv_te , archi3, epoch3, seed2)\n",
        "    print('Third Seed')\n",
        "    Ypred_temp3 = Neural_net(X_all, y_all, num_tr_cv_te , archi3, epoch3, seed3)  \n",
        "\n",
        "    if i==13:\n",
        "        Y_predict_NN3_1 = Ypred_temp1\n",
        "        Y_predict_NN3_2 = Ypred_temp2\n",
        "        Y_predict_NN3_3 = Ypred_temp3\n",
        "    else:\n",
        "        Y_predict_NN3_1 = np.concatenate((Y_predict_NN3_1, Ypred_temp1), axis=0)\n",
        "        Y_predict_NN3_2 = np.concatenate((Y_predict_NN3_2, Ypred_temp2), axis=0)\n",
        "        Y_predict_NN3_3 = np.concatenate((Y_predict_NN3_3, Ypred_temp3), axis=0)\n",
        "\n",
        "\n",
        "Y_predict_NN3_1 = pd.DataFrame(Y_predict_NN3_1, columns=['NN3'])\n",
        "Y_predict_NN3_2 = pd.DataFrame(Y_predict_NN3_2, columns=['NN3'])\n",
        "Y_predict_NN3_3 = pd.DataFrame(Y_predict_NN3_3, columns=['NN3'])\n",
        "Y_predict_NN3_1.to_csv('/content/drive/MyDrive/y_NN3_1_3rd.csv', index = False)\n",
        "Y_predict_NN3_2.to_csv('/content/drive/MyDrive/y_NN3_2_3rd.csv', index = False)\n",
        "Y_predict_NN3_3.to_csv('/content/drive/MyDrive/y_NN3_3_3rd.csv', index = False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "First Seed\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.04331872649490833\n",
            "the epoch number 0 (valid_loss) : 0.04723246174596124\n",
            "the epoch number 5 (train_loss) : 0.030881229732185603\n",
            "the epoch number 5 (valid_loss) : 0.0471673638449382\n",
            "the epoch number 10 (train_loss) : 0.030888958554714917\n",
            "the epoch number 10 (valid_loss) : 0.047161900517293964\n",
            "the epoch number 15 (train_loss) : 0.030888394368812442\n",
            "the epoch number 15 (valid_loss) : 0.04714641044453039\n",
            "the epoch number 20 (train_loss) : 0.03088035564869642\n",
            "the epoch number 20 (valid_loss) : 0.0471860733262058\n",
            "the epoch number 25 (train_loss) : 0.03088559340685606\n",
            "the epoch number 25 (valid_loss) : 0.04716961587763439\n",
            "the epoch number 30 (train_loss) : 0.03087627749890089\n",
            "the epoch number 30 (valid_loss) : 0.04714400223377398\n",
            "the epoch number 35 (train_loss) : 0.030882009994238614\n",
            "the epoch number 35 (valid_loss) : 0.0471669784983841\n",
            "the epoch number 40 (train_loss) : 0.030878897039219737\n",
            "the epoch number 40 (valid_loss) : 0.04717159482760955\n",
            "the epoch number 45 (train_loss) : 0.030860382495447994\n",
            "the epoch number 45 (valid_loss) : 0.047171386590195916\n",
            "the epoch number 50 (train_loss) : 0.030887540355324747\n",
            "the epoch number 50 (valid_loss) : 0.04718426239313716\n",
            "the epoch number 55 (train_loss) : 0.030878239683806895\n",
            "the epoch number 55 (valid_loss) : 0.04716557867319907\n",
            "Early stopping! at 55th Epochs\n",
            "Second Seed\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.06212857708334923\n",
            "the epoch number 0 (valid_loss) : 0.050257301621012766\n",
            "the epoch number 5 (train_loss) : 0.0330982926953584\n",
            "the epoch number 5 (valid_loss) : 0.05016976279222359\n",
            "the epoch number 10 (train_loss) : 0.033096950752660635\n",
            "the epoch number 10 (valid_loss) : 0.05019906393678512\n",
            "the epoch number 15 (train_loss) : 0.03308315917849541\n",
            "the epoch number 15 (valid_loss) : 0.05008552959030968\n",
            "the epoch number 20 (train_loss) : 0.033107717037200925\n",
            "the epoch number 20 (valid_loss) : 0.05011906894713135\n",
            "the epoch number 25 (train_loss) : 0.03309546324424446\n",
            "the epoch number 25 (valid_loss) : 0.05013660057368925\n",
            "the epoch number 30 (train_loss) : 0.0330937818903476\n",
            "the epoch number 30 (valid_loss) : 0.05018547609827276\n",
            "the epoch number 35 (train_loss) : 0.033091447576880456\n",
            "the epoch number 35 (valid_loss) : 0.050221485227851546\n",
            "Early stopping! at 35th Epochs\n",
            "Third Seed\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.056375997327268126\n",
            "the epoch number 0 (valid_loss) : 0.05346025981135288\n",
            "the epoch number 5 (train_loss) : 0.0338737880717963\n",
            "the epoch number 5 (valid_loss) : 0.05313524010322862\n",
            "the epoch number 10 (train_loss) : 0.03387163957580924\n",
            "the epoch number 10 (valid_loss) : 0.053152657603308305\n",
            "the epoch number 15 (train_loss) : 0.03386360506527126\n",
            "the epoch number 15 (valid_loss) : 0.053202850680987714\n",
            "the epoch number 20 (train_loss) : 0.0338603450730443\n",
            "the epoch number 20 (valid_loss) : 0.05316348373889923\n",
            "the epoch number 25 (train_loss) : 0.033874661698937415\n",
            "the epoch number 25 (valid_loss) : 0.05323476590595003\n",
            "the epoch number 30 (train_loss) : 0.03387558217160404\n",
            "the epoch number 30 (valid_loss) : 0.05313288666686769\n",
            "the epoch number 35 (train_loss) : 0.03386392924934625\n",
            "the epoch number 35 (valid_loss) : 0.05318220035504487\n",
            "the epoch number 40 (train_loss) : 0.0338709310349077\n",
            "the epoch number 40 (valid_loss) : 0.05321653989159455\n",
            "the epoch number 45 (train_loss) : 0.03387203224003315\n",
            "the epoch number 45 (valid_loss) : 0.0532457464516668\n",
            "the epoch number 50 (train_loss) : 0.03387763995677233\n",
            "the epoch number 50 (valid_loss) : 0.053213398082781645\n",
            "the epoch number 55 (train_loss) : 0.03386737808585167\n",
            "the epoch number 55 (valid_loss) : 0.05325479795998436\n",
            "the epoch number 60 (train_loss) : 0.03385796212591231\n",
            "the epoch number 60 (valid_loss) : 0.05321789791775962\n",
            "Early stopping! at 62th Epochs\n",
            "14\n",
            "First Seed\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.04718076790819801\n",
            "the epoch number 0 (valid_loss) : 0.05045429524830264\n",
            "the epoch number 5 (train_loss) : 0.03218041321536376\n",
            "the epoch number 5 (valid_loss) : 0.050397449642674536\n",
            "the epoch number 10 (train_loss) : 0.032184752154548024\n",
            "the epoch number 10 (valid_loss) : 0.05043983949810012\n",
            "the epoch number 15 (train_loss) : 0.03218596260906396\n",
            "the epoch number 15 (valid_loss) : 0.05038414672653899\n",
            "the epoch number 20 (train_loss) : 0.03218025857167786\n",
            "the epoch number 20 (valid_loss) : 0.05038374398126561\n",
            "the epoch number 25 (train_loss) : 0.0321782904884544\n",
            "the epoch number 25 (valid_loss) : 0.050419380203780964\n",
            "the epoch number 30 (train_loss) : 0.03218611814434777\n",
            "the epoch number 30 (valid_loss) : 0.05044273350738052\n",
            "the epoch number 35 (train_loss) : 0.03217661838042792\n",
            "the epoch number 35 (valid_loss) : 0.050436848472071506\n",
            "the epoch number 40 (train_loss) : 0.03218532253003798\n",
            "the epoch number 40 (valid_loss) : 0.05044468762910264\n",
            "Early stopping! at 43th Epochs\n",
            "Second Seed\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.06078434313572414\n",
            "the epoch number 0 (valid_loss) : 0.04998537929903748\n",
            "the epoch number 5 (train_loss) : 0.03315168447015692\n",
            "the epoch number 5 (valid_loss) : 0.04994132220108285\n",
            "the epoch number 10 (train_loss) : 0.033150282569264916\n",
            "the epoch number 10 (valid_loss) : 0.049959559280138746\n",
            "the epoch number 15 (train_loss) : 0.03314925386830811\n",
            "the epoch number 15 (valid_loss) : 0.0499980693253187\n",
            "the epoch number 20 (train_loss) : 0.03314603549997671\n",
            "the epoch number 20 (valid_loss) : 0.049879033118486404\n",
            "the epoch number 25 (train_loss) : 0.03314808812610346\n",
            "the epoch number 25 (valid_loss) : 0.049931458683095425\n",
            "Early stopping! at 28th Epochs\n",
            "Third Seed\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.0569065112832457\n",
            "the epoch number 0 (valid_loss) : 0.05556865475880794\n",
            "the epoch number 5 (train_loss) : 0.03510387143852869\n",
            "the epoch number 5 (valid_loss) : 0.0553848378551312\n",
            "the epoch number 10 (train_loss) : 0.03508729763081853\n",
            "the epoch number 10 (valid_loss) : 0.055381939738479435\n",
            "the epoch number 15 (train_loss) : 0.035097806674750494\n",
            "the epoch number 15 (valid_loss) : 0.055320483528905444\n",
            "the epoch number 20 (train_loss) : 0.035096922138997164\n",
            "the epoch number 20 (valid_loss) : 0.05544460341971145\n",
            "the epoch number 25 (train_loss) : 0.03509582881043308\n",
            "the epoch number 25 (valid_loss) : 0.05536383982652273\n",
            "the epoch number 30 (train_loss) : 0.03509900323446328\n",
            "the epoch number 30 (valid_loss) : 0.05539845547869674\n",
            "the epoch number 35 (train_loss) : 0.03509045146864737\n",
            "the epoch number 35 (valid_loss) : 0.05543184713420705\n",
            "the epoch number 40 (train_loss) : 0.035098659775056544\n",
            "the epoch number 40 (valid_loss) : 0.055320281153305985\n",
            "the epoch number 45 (train_loss) : 0.03509588949205751\n",
            "the epoch number 45 (valid_loss) : 0.05541363294817444\n",
            "the epoch number 50 (train_loss) : 0.0351006079253286\n",
            "the epoch number 50 (valid_loss) : 0.055319009396510244\n",
            "the epoch number 55 (train_loss) : 0.03511001409795047\n",
            "the epoch number 55 (valid_loss) : 0.05535616942195811\n",
            "the epoch number 60 (train_loss) : 0.03509667495450985\n",
            "the epoch number 60 (valid_loss) : 0.05539256560369434\n",
            "the epoch number 65 (train_loss) : 0.03510107594361237\n",
            "the epoch number 65 (valid_loss) : 0.055401802031148195\n",
            "the epoch number 70 (train_loss) : 0.03509773009443452\n",
            "the epoch number 70 (valid_loss) : 0.055419665785172045\n",
            "Early stopping! at 73th Epochs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah6hN7gZb9NA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9d12e2e-0014-45c3-ae0e-f4d434d7eb13"
      },
      "source": [
        "\n",
        "for i in range(15,23): \n",
        "    print(i)\n",
        "    \n",
        "    num_train_months = All_sp_len-OOS_len-CV_len+12*i\n",
        "    num_cv_months = CV_len    #120 months\n",
        "    num_test_months = 12   # for each estimation, predict 12months\n",
        "    \n",
        "    num_train = sum(date_num_firm[:num_train_months])\n",
        "    num_cv = sum(date_num_firm[num_train_months:(num_train_months+num_cv_months)])\n",
        "    num_test = sum(date_num_firm[(num_train_months+num_cv_months):(num_train_months+num_cv_months+num_test_months)])\n",
        "    \n",
        "    num_tr_cv_te = [num_train, num_cv, num_test]\n",
        "    \n",
        "    # train + val + test \n",
        "    # split them in function (num_train, num_cv, num_test is input variable) \n",
        "    X_all = X_no_inter.iloc[:sum(num_tr_cv_te),:].to_numpy()    # no CV\n",
        "    y_all = y.iloc[:sum(num_tr_cv_te)].to_numpy().reshape(-1,1)\n",
        "    \n",
        "    print('First Seed')\n",
        "    Ypred_temp1 = Neural_net(X_all, y_all, num_tr_cv_te , archi3, epoch3, seed1)\n",
        "    print('Second Seed')\n",
        "    Ypred_temp2 = Neural_net(X_all, y_all, num_tr_cv_te , archi3, epoch3, seed2)\n",
        "    print('Third Seed')\n",
        "    Ypred_temp3 = Neural_net(X_all, y_all, num_tr_cv_te , archi3, epoch3, seed3)  \n",
        "\n",
        "    if i==15:\n",
        "        Y_predict_NN3_1 = Ypred_temp1\n",
        "        Y_predict_NN3_2 = Ypred_temp2\n",
        "        Y_predict_NN3_3 = Ypred_temp3\n",
        "    else:\n",
        "        Y_predict_NN3_1 = np.concatenate((Y_predict_NN3_1, Ypred_temp1), axis=0)\n",
        "        Y_predict_NN3_2 = np.concatenate((Y_predict_NN3_2, Ypred_temp2), axis=0)\n",
        "        Y_predict_NN3_3 = np.concatenate((Y_predict_NN3_3, Ypred_temp3), axis=0)\n",
        "\n",
        "\n",
        "Y_predict_NN3_1 = pd.DataFrame(Y_predict_NN3_1, columns=['NN3'])\n",
        "Y_predict_NN3_2 = pd.DataFrame(Y_predict_NN3_2, columns=['NN3'])\n",
        "Y_predict_NN3_3 = pd.DataFrame(Y_predict_NN3_3, columns=['NN3'])\n",
        "Y_predict_NN3_1.to_csv('/content/drive/MyDrive/y_NN3_1_4th.csv', index = False)\n",
        "Y_predict_NN3_2.to_csv('/content/drive/MyDrive/y_NN3_2_4th.csv', index = False)\n",
        "Y_predict_NN3_3.to_csv('/content/drive/MyDrive/y_NN3_3_4th.csv', index = False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n",
            "First Seed\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.04278952561251752\n",
            "the epoch number 0 (valid_loss) : 0.04753735182077988\n",
            "the epoch number 5 (train_loss) : 0.03119281582903486\n",
            "the epoch number 5 (valid_loss) : 0.04756324381931969\n",
            "the epoch number 10 (train_loss) : 0.031193170503520214\n",
            "the epoch number 10 (valid_loss) : 0.047533216716154764\n",
            "the epoch number 15 (train_loss) : 0.031198710874394252\n",
            "the epoch number 15 (valid_loss) : 0.047490483684384306\n",
            "the epoch number 20 (train_loss) : 0.031198274117667932\n",
            "the epoch number 20 (valid_loss) : 0.047478586694468625\n",
            "the epoch number 25 (train_loss) : 0.03118994286669804\n",
            "the epoch number 25 (valid_loss) : 0.04750184258041174\n",
            "the epoch number 30 (train_loss) : 0.031204818101885082\n",
            "the epoch number 30 (valid_loss) : 0.04751687318734501\n",
            "the epoch number 35 (train_loss) : 0.03119455676458709\n",
            "the epoch number 35 (valid_loss) : 0.04753960371017456\n",
            "the epoch number 40 (train_loss) : 0.031199848036038445\n",
            "the epoch number 40 (valid_loss) : 0.04755449372789134\n",
            "the epoch number 45 (train_loss) : 0.03119642541718644\n",
            "the epoch number 45 (valid_loss) : 0.047483484641365384\n",
            "Early stopping! at 49th Epochs\n",
            "Second Seed\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.06062146954171292\n",
            "the epoch number 0 (valid_loss) : 0.05047874029563821\n",
            "the epoch number 5 (train_loss) : 0.033206906203214114\n",
            "the epoch number 5 (valid_loss) : 0.05047284306391426\n",
            "the epoch number 10 (train_loss) : 0.03321652543974352\n",
            "the epoch number 10 (valid_loss) : 0.0504818568735019\n",
            "the epoch number 15 (train_loss) : 0.03320956024601384\n",
            "the epoch number 15 (valid_loss) : 0.0504083674563014\n",
            "the epoch number 20 (train_loss) : 0.03321501171333833\n",
            "the epoch number 20 (valid_loss) : 0.050467694874690924\n",
            "the epoch number 25 (train_loss) : 0.03320765938307788\n",
            "the epoch number 25 (valid_loss) : 0.050523592240136604\n",
            "the epoch number 30 (train_loss) : 0.03320466315054947\n",
            "the epoch number 30 (valid_loss) : 0.050490844832814255\n",
            "the epoch number 35 (train_loss) : 0.033213040623646065\n",
            "the epoch number 35 (valid_loss) : 0.05044902239156806\n",
            "the epoch number 40 (train_loss) : 0.03320075141114963\n",
            "the epoch number 40 (valid_loss) : 0.0505824258470017\n",
            "the epoch number 45 (train_loss) : 0.033207710253427156\n",
            "the epoch number 45 (valid_loss) : 0.050473910505356996\n",
            "Early stopping! at 48th Epochs\n",
            "Third Seed\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.05583641073154705\n",
            "the epoch number 0 (valid_loss) : 0.09471673677149026\n",
            "the epoch number 5 (train_loss) : 0.03517284504398032\n",
            "the epoch number 5 (valid_loss) : 0.09428111003792804\n",
            "the epoch number 10 (train_loss) : 0.035189648427337676\n",
            "the epoch number 10 (valid_loss) : 0.09419687516663386\n",
            "the epoch number 15 (train_loss) : 0.03518323297402612\n",
            "the epoch number 15 (valid_loss) : 0.09443894699215889\n",
            "the epoch number 20 (train_loss) : 0.03518408271777737\n",
            "the epoch number 20 (valid_loss) : 0.09379447559299676\n",
            "the epoch number 25 (train_loss) : 0.035182104789995935\n",
            "the epoch number 25 (valid_loss) : 0.09403047895301943\n",
            "the epoch number 30 (train_loss) : 0.03518023291552389\n",
            "the epoch number 30 (valid_loss) : 0.09470190221200818\n",
            "the epoch number 35 (train_loss) : 0.03518641391047486\n",
            "the epoch number 35 (valid_loss) : 0.09410037696361542\n",
            "the epoch number 40 (train_loss) : 0.035182449018565924\n",
            "the epoch number 40 (valid_loss) : 0.0942039650419484\n",
            "the epoch number 45 (train_loss) : 0.03517968937553264\n",
            "the epoch number 45 (valid_loss) : 0.09368373518404753\n",
            "the epoch number 50 (train_loss) : 0.0351771248319933\n",
            "the epoch number 50 (valid_loss) : 0.09402249180104422\n",
            "Early stopping! at 52th Epochs\n",
            "16\n",
            "First Seed\n",
            "NN_fwd_model(\n",
            "  (nn_module): Sequential(\n",
            "    (linear1): Linear(in_features=168, out_features=32, bias=True)\n",
            "    (Relu1): ReLU()\n",
            "    (BN1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (Relu2): ReLU()\n",
            "    (BN2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (linear3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (Relu3): ReLU()\n",
            "    (BN3): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (lastlinear): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "the epoch number 0 (train_loss) : 0.043208444554708965\n",
            "the epoch number 0 (valid_loss) : 0.047343881883188686\n",
            "the epoch number 5 (train_loss) : 0.031492851754156954\n",
            "the epoch number 5 (valid_loss) : 0.047342614559209455\n",
            "the epoch number 10 (train_loss) : 0.03144506494809165\n",
            "the epoch number 10 (valid_loss) : 0.04736070786561586\n",
            "the epoch number 15 (train_loss) : 0.03149047348266228\n",
            "the epoch number 15 (valid_loss) : 0.04730306028396682\n",
            "the epoch number 20 (train_loss) : 0.03149273564927598\n",
            "the epoch number 20 (valid_loss) : 0.047269679012551774\n",
            "the epoch number 25 (train_loss) : 0.0314927449147416\n",
            "the epoch number 25 (valid_loss) : 0.047326652712262836\n",
            "the epoch number 30 (train_loss) : 0.03148978904017016\n",
            "the epoch number 30 (valid_loss) : 0.04728720815176458\n",
            "the epoch number 35 (train_loss) : 0.031486226285561025\n",
            "the epoch number 35 (valid_loss) : 0.04728329686068856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rWmq1McVIIU"
      },
      "source": [
        ""
      ]
    }
  ]
}