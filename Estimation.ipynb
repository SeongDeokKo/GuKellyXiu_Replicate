{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Estimation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOD7rt97Gn8xQusOxmsMx3+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongDeokKo/GuKellyXiu_Replicate/blob/main/Estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFQAaPGIzHVH",
        "outputId": "ede86eab-8d87-4691-d9f2-76ff1f6d5e68"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33wcZuU653ZS"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/')\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from collections import Counter\n",
        "import FunLib_stock as FL\n",
        "import multiprocessing as mp"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzL2d8oc1S6H"
      },
      "source": [
        "new_firm_data = pd.read_csv('/content/drive/MyDrive/x_y_wo_inter.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC_H-R8b3qX_"
      },
      "source": [
        "new_firm_data[new_firm_data.columns[2:96]] = new_firm_data[new_firm_data.columns[2:96]].astype('float32')\n",
        "new_firm_data[new_firm_data.columns[0:2]] = new_firm_data[new_firm_data.columns[0:2]].astype('int32')\n",
        "new_firm_data[new_firm_data.columns[96:170]] = new_firm_data[new_firm_data.columns[96:170]].astype('int8')\n",
        "new_firm_data[new_firm_data.columns[170]] = new_firm_data[new_firm_data.columns[170]].astype('float32')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWVWPG661S81"
      },
      "source": [
        "\n",
        "def R2OOS(y_true, y_forecast):\n",
        "    \n",
        "    import numpy as np\n",
        "   \n",
        "    SSres = np.nansum(np.square(y_true-y_forecast))\n",
        "    SStot = np.nansum(np.square(y_true))\n",
        "\n",
        "    return 1-SSres/SStot\n",
        "\n",
        "\n",
        "\n",
        "# =========================================================================\n",
        "#   PCR, 94 + dummy variable(no intersection term), Use cross-validation to select the number of PCA components  \n",
        "# =========================================================================\n",
        "\n",
        "def Pca_regression(X,Y,numpc,num_t_v):\n",
        "    # numpc (list) : # of principal component ex[3,4,5,6,7]\n",
        "    # num_t_v (list) : # of training set & cross-val set   ex[100, 10]\n",
        "    # X consists of Traing, Val and Test set\n",
        "    \n",
        "    import numpy as np \n",
        "    from sklearn.decomposition import PCA\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    \n",
        "    num_train = num_t_v[0]\n",
        "    num_val = num_t_v[1]\n",
        "    num_test = X.shape[0] - (num_train + num_val)\n",
        "    \n",
        "    # Split data into training and test\n",
        "    X_train = X[:num_train,:]\n",
        "    Y_train = Y[:num_train,:]\n",
        "    \n",
        "    X_val = X[num_train:(num_train+num_val),:]\n",
        "    Y_val = Y[num_train:(num_train+num_val),:]\n",
        "    \n",
        "    X_test = X[(num_train+num_val):,:]\n",
        "    \n",
        "       \n",
        "    # Scale Inputs for Training\n",
        "    X_scaler = StandardScaler()\n",
        "    X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "    \n",
        "    X_val_scaled = X_scaler.transform(X_val)\n",
        "    X_test_scaled = X_scaler.transform(X_test)\n",
        "    \n",
        "    \n",
        "    # use cross-validation mean-squared-error to determine the number of component \n",
        "    mse = np.full((len(numpc),1),np.nan, dtype = np.float32)\n",
        "\n",
        "    for i in range(len(numpc)):\n",
        "        pca = PCA(n_components = numpc[i])\n",
        "        principalComponents = pca.fit_transform(X_train_scaled)\n",
        "        \n",
        "        X_val_weighted = pca.transform(X_val_scaled)\n",
        "        \n",
        "        line_fitter = LinearRegression()\n",
        "        line_fitter.fit(principalComponents, Y_train)\n",
        "        \n",
        "        Ypred_val = np.full((num_val,1),np.nan, dtype = np.float32)\n",
        "        for j in range(num_val):\n",
        "            Ypred_val[j,0] = line_fitter.predict(X_val_weighted[j,:].reshape(1,-1))\n",
        "                   \n",
        "        mse[i,0] = mean_squared_error(Y_val.reshape(-1), Ypred_val.reshape(-1))\n",
        "    \n",
        "    \n",
        "    argmin_numpc = numpc[np.argmin(mse)]\n",
        "    \n",
        "    pca = PCA(n_components = argmin_numpc)\n",
        "    principalComponents = pca.fit_transform(X_train_scaled)\n",
        "    \n",
        "    X_test_weighted = pca.transform(X_test_scaled)\n",
        "    \n",
        "    line_fitter = LinearRegression()\n",
        "    line_fitter.fit(principalComponents, Y_train)\n",
        "        \n",
        "    Ypred_test = np.full((num_test,1),np.nan, dtype = np.float32)\n",
        "    for j in range(num_test):\n",
        "        Ypred_test[j,0]=line_fitter.predict(X_test_weighted[j,:].reshape(1,-1))\n",
        "        \n",
        "          \n",
        "    return Ypred_test, argmin_numpc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# =========================================================================\n",
        "#   PLS, 94 + dummy variable(no intersection term), Use cross-validation to select the number of components  \n",
        "# =========================================================================\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvgm4aMFWhUZ"
      },
      "source": [
        "def elastic_net(X,Y,num):\n",
        "    # num_t_v (list) : # of training set & cross-val set   ex[100, 10]\n",
        "    # X consists of Traing, Val and Test set\n",
        "    \n",
        "    import numpy as np\n",
        "    from sklearn.linear_model import ElasticNetCV\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.model_selection import PredefinedSplit\n",
        "    \n",
        "    num_test = sum(num[420:])\n",
        "    num_start = sum(num[0:84])\n",
        "    Ypred_test = np.full((num_test,1),np.nan, dtype = np.float32)\n",
        "    for i in range(25):\n",
        "      num_trian = sum(num[84:(276 + 12*i)])\n",
        "      num_val = sum(num[(276 + 12*i):(420 + 12*i)])\n",
        "      num_test_start = sum(num[420:]) - sum(num[420+12*i:])\n",
        "      num_pred = sum(num[420+12*i:420+12*(i+1)])\n",
        "      if i == 24:\n",
        "        num_pred = sum(num[(420+12*i):])\n",
        "      # Split data into training and test\n",
        "      X_train = X[num_start:(num_start + num_train+num_val),:]   # train + validation\n",
        "      Y_train = Y[num_start:(num_start + num_train+num_val),:]   # train + validation\n",
        "    \n",
        "      # Scale Inputs for Training\n",
        "      X_scaler = StandardScaler()\n",
        "      X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "      XX = X_scaler.transform(X)\n",
        "    \n",
        "      # pre-define validation \n",
        "      test_fold =  np.concatenate(((np.full((num_train),-1),np.full((num_val),0))))\n",
        "      ps = PredefinedSplit(test_fold.tolist())\n",
        "    \n",
        "      # fit & predict \n",
        "      model = ElasticNetCV(cv=ps, max_iter=5000, n_jobs=-1, l1_ratio=[.1, .3, .5, .7, .9], \n",
        "                         random_state=42)\n",
        "      model = model.fit(X_train_scaled, Y_train.reshape(-1))\n",
        "    \n",
        "      for j in range(num_pred):\n",
        "        Ypred_test[num_test_start + j,0]=model.predict(XX[ num_start + num_train + num_val +j,:].reshape(1,-1))\n",
        "        \n",
        "    return Ypred_test\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abYtqcd1WwVz"
      },
      "source": [
        "def Pls_regression(X,Y,numpls,num):\n",
        "    # numpls (list) : # of component ex[3,4,5,6,7]\n",
        "    # num_t_v (list) : # of training set & cross-val set   ex[100, 10]\n",
        "    # X consists of Traing, Val and Test set\n",
        "    \n",
        "    import numpy as np \n",
        "    from sklearn.cross_decomposition import PLSRegression\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    \n",
        "    num_test = sum(num[420:])\n",
        "    num_start = sum(num[0:84])\n",
        "    Ypred_test = np.full((num_test,1),np.nan, dtype = np.float32)\n",
        "    for i in range(25):\n",
        "      num_trian = sum(num[84:(276 + 12*i)])\n",
        "      num_val = sum(num[(276 + 12*i):(420 + 12*i)])\n",
        "      num_test_start = sum(num[420:]) - sum(num[420+12*i:])\n",
        "      num_pred = sum(num[420+12*i:420+12*(i+1)])\n",
        "      if i == 24:\n",
        "        num_pred = sum(num[(420+12*i):])\n",
        "      # Split data into training and test\n",
        "      X_train = X[num_start:(num_start +num_train),:]   # train\n",
        "      Y_train = Y[num_start:(num_start +num_train),:]   # train \n",
        "      X_val = X[num_start:(num_start+num_train+num_val),:]\n",
        "      Y_val = Y[num_start:(num_start+num_train+num_val),:]\n",
        "      # Scale Inputs for Training\n",
        "      X_scaler = StandardScaler()\n",
        "      X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "      X_val_scaled = X_scaler.transform(X_val)\n",
        "      XX = X_scaler.transform(X)\n",
        "\n",
        "      # use cross-validation mean-squared-error to determine the number of component \n",
        "      mse = np.full((len(numpls),1),np.nan, dtype = np.float32)\n",
        "      \n",
        "      for j in range(len(numpls)):\n",
        "          pls = PLSRegression(n_components = numpls[j])\n",
        "          pls.fit(X_train_scaled, Y_train)\n",
        "                \n",
        "          Ypred_val = np.full((num_val,1),np.nan, dtype = np.float32)\n",
        "          for k in range(num_val):\n",
        "              Ypred_val[j,0]=pls.predict(X_val_scaled[k,:].reshape(1,-1))          \n",
        "          mse[j,0] = mean_squared_error(Y_val.reshape(-1), Ypred_val.reshape(-1))\n",
        "    \n",
        "      argmin_numpls = numpls[np.argmin(mse)]\n",
        "      pls = PLSRegression(n_components = argmin_numpls)\n",
        "      pls.fit(X_train_scaled, Y_train)\n",
        "    \n",
        "      for u in range(num_pred):\n",
        "        Ypred_test[num_test_start+u,0]=pls.predict(XX[ num_start + num_train + num_val + u,:].reshape(1,-1))          \n",
        "              \n",
        "    return Ypred_test\n"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnXYJNyNvZRl"
      },
      "source": [
        "X = X_no_inter.to_numpy()\n",
        "Y = y.to_numpy().reshape(-1,1)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74vVUoCpvZUS"
      },
      "source": [
        "num_test = sum(num[420:])\n",
        "num_start = sum(num[0:84])\n",
        "Ypred_test = np.full((num_test,1),np.nan, dtype = np.float32)\n",
        "i = 1\n",
        "num_trian = sum(num[84:(276 + 12*i)])\n",
        "num_val = sum(num[(276 + 12*i):(420 + 12*i)])\n",
        "num_test_start = sum(num[420:]) - sum(num[420+12*i:])\n",
        "num_pred = sum(num[420+12*i:420+12*(i+1)])\n",
        "if i == 24:\n",
        "  num_pred = sum(num[(420+12*i):])\n",
        "# Split data into training and test\n",
        "      "
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLQk_UNMwOKQ"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a_E42s_vvf6"
      },
      "source": [
        "X_train = X[num_start:(num_start + num_train),:]   # train\n",
        "Y_train = Y[num_start:(num_start +num_train),:]   # train \n",
        "X_val = X[num_start:(num_start+num_train+num_val),:]\n",
        "Y_val = Y[num_start:(num_start+num_train+num_val),:]\n",
        "# Scale Inputs for Training\n",
        "X_scaler = StandardScaler()\n",
        "X_train_scaled = X_scaler.fit_transform(X_train)\n",
        "X_val_scaled = X_scaler.transform(X_val)\n",
        "XX = X_scaler.transform(X)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11JlMI4-v6I1",
        "outputId": "1baaf245-1f60-4bff-a117-4e29af52034b"
      },
      "source": [
        "X_val_scaled"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.09353273, -0.54263586, -0.6080939 , ..., -0.05478966,\n",
              "        -0.15216303,  0.        ],\n",
              "       [-0.3703877 , -0.69055575, -0.69403875, ..., -0.05478966,\n",
              "        -0.15216303,  0.        ],\n",
              "       [-0.16017693, -0.97590506, -0.8335567 , ..., -0.05478966,\n",
              "        -0.15216303,  0.        ],\n",
              "       ...,\n",
              "       [ 1.5197862 , -1.1758326 , -0.9106885 , ..., -0.05478966,\n",
              "        -0.15216303,  0.        ],\n",
              "       [-0.3282353 , -0.24680927, -0.408312  , ..., -0.05478966,\n",
              "        -0.15216303,  0.        ],\n",
              "       [-0.36953044, -1.7310886 , -1.0357853 , ..., -0.05478966,\n",
              "        -0.15216303,  0.        ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOMA-8o05KHS"
      },
      "source": [
        "# X_no_inter (168) : 195703 ~ 201612, y(1) :195704 ~ 201701\n",
        "# X-195703 & y-195704 are in the same row. \n",
        "\n",
        "X_no_inter = new_firm_data.iloc[:,2:170]     # without intersect terms\n",
        "y = new_firm_data.iloc[:,-1]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saRX1B453Kh7",
        "outputId": "d92c81c1-921e-4577-e89c-ce221bfff3f3"
      },
      "source": [
        "sum(num[0:72])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85025"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTgZby-t5fbK"
      },
      "source": [
        "\n",
        "num_est = 1  # We estimate parameter 1 time, here not use\n",
        "\n",
        "# if we estimate parameters more than 1 time(i.e using longer data), we should set below # recursively\n",
        "# Train \n",
        "# Validation \n",
        "# Test \n",
        "\n",
        "num_start = sum(num[0:84])\n",
        "num_train = sum(num[84:(216+12*5)])\n",
        "num_val = sum(num[(216+12*5):(216+144+60)])\n",
        "num_test = sum(num[(216+144+60):])\n",
        "num_t_v = [num_train, num_val]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPi2_Chb3_yA",
        "outputId": "65ab4cd9-de1e-49dc-c47d-afec0a46ce85"
      },
      "source": [
        "num_start, num_train , num_val , num_test"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109501, 662229, 884336, 2053843)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiK2HFY03BFd"
      },
      "source": [
        "y_true = y.iloc[-num_test:].to_numpy().reshape(-1,1)  # for caluclating R2oos"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxcaHYHS3BDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d660a6-9b5b-4dfa-e84f-fbe92d767fc2"
      },
      "source": [
        "\n",
        "# Computational Ressources: Determine Number of available cores\n",
        "ncpus = mp.cpu_count()\n",
        "print(\"CPU count is: \"+str(ncpus))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU count is: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5pLnw1YMl9L",
        "outputId": "07bb5c0b-7a9f-43b0-9f68-6e8074b6471b"
      },
      "source": [
        "sum(num[420+12*22:420+12*23]), sum(num[420+12*23:]) , sum(num[420+12*24:])"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(67665, 125154, 56442)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFLbfiHmNP3P"
      },
      "source": [
        "from sklearn.linear_model import HuberRegressor\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm_7f0qeM-uY"
      },
      "source": [
        "Y_pred_ols = np.full((num_test,1),np.nan, dtype = np.float32 )\n",
        "Y_pred_ols_huber = np.full((num_test,1),np.nan, dtype = np.float32 )"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5_6d-sqOl3s"
      },
      "source": [
        "Rolling Version \n",
        "\n",
        "i = 0, 64-80, 80-92, 92~93 ,\n",
        "\n",
        "i = 1, 64-81, 81-93, 93~94\n",
        "\n",
        ";;;;\n",
        "i = 24, 64-04, 04-16, 16-16년 12월까지 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNLodmUFLj0z",
        "outputId": "8f776074-f54b-4240-ffa1-3700ad7f0ffc"
      },
      "source": [
        "Y_pred_ols = np.full((num_test,1),np.nan, dtype = np.float32 )\n",
        "for i in range(25):\n",
        "  num_trian = sum(num[84:(276 + 12*i)])\n",
        "  num_val = sum(num[(276 + 12*i):(420 + 12*i)])\n",
        "  num_test_start = sum(num[420:]) - sum(num[420+12*i:])\n",
        "  num_pred = sum(num[420+12*i:420+12*(i+1)])\n",
        "  X_train_ols = X_no_inter.iloc[num_start:(num_start+ num_train+num_val),:].to_numpy()\n",
        "  y_train_ols = y.iloc[num_start:(num_start +num_train+num_val)].to_numpy()\n",
        "  reg = LinearRegression().fit(X_train_ols, y_train_ols)\n",
        "  reg_huber = HuberRegressor(max_iter=500, alpha=0).fit(X_train_ols, y_train_ols)\n",
        "  if i == 24:\n",
        "    print('it is 24')\n",
        "    num_pred = sum(num[(420+12*i):])\n",
        "  for j in range(num_pred):\n",
        "    Y_pred_ols[num_test_start + j,0] = reg.predict(X_no_inter.iloc[(num_start + num_train + num_val + j),:].to_numpy().reshape(1,-1)) \n",
        "    Y_pred_ols_huber[num_test_start + j,0] = reg_huber.predict(X_no_inter.iloc[(num_start + num_train+num_val+j),:].to_numpy().reshape(1,-1) )"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it is 24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvP5ULgXkP_z",
        "outputId": "7f6a63d1-8453-4fcf-e75c-977fc87bbebb"
      },
      "source": [
        "print('R2OOS, Huber Loss - Linear regression without intersection terms : ', FL.R2OOS(y_true, Y_pred_ols))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2OOS, Huber Loss - Linear regression without intersection terms :  -0.0017085075378417969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VakslcngkP7S",
        "outputId": "d30ad62f-93cd-438c-b3a3-f78530fb02ef"
      },
      "source": [
        "print('R2OOS, Huber Loss - Linear regression without intersection terms : ', FL.R2OOS(y_true, Y_pred_ols_huber))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2OOS, Huber Loss - Linear regression without intersection terms :  0.0004981160163879395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyFEiA5lkqCj"
      },
      "source": [
        "Y_pred_elastic = elastic_net(X_no_inter.to_numpy(), y.to_numpy().reshape(-1,1), num)\n",
        "numpls = [3,5,10,15,20]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNXdtiyhkp9F",
        "outputId": "ba5c8d32-dbae-4ec4-9644-4d2840c4dcf5"
      },
      "source": [
        "print('R2OOS, Elastic-net - without intersection terms : ', FL.R2OOS(y_true, Y_pred_elastic))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2OOS, Elastic-net - without intersection terms :  0.0016314983367919922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufL5a9Prt3VV"
      },
      "source": [
        "Y_pred_pls = Pls_regression(X_no_inter.to_numpy(), y.to_numpy().reshape(-1,1) ,numpls,num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqlRsc-tlEXG"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKbhSPd2TX6D",
        "outputId": "9deb2dcb-482a-4cc7-9a54-4263c03ee5f1"
      },
      "source": [
        "print('R2OOS, Huber Loss - Linear regression without intersection terms : ', FL.R2OOS(y_true, Y_pred_ols_huber))\n",
        "print('R2OOS, Principal Components Regression - without intersection terms : ', FL.R2OOS(y_true, Y_pred_pca)) \n",
        "print('R2OOS, Partial Least Square - without intersection terms : ', FL.R2OOS(y_true, Y_pred_pls)) \n",
        "print('R2OOS, Elastic-net - without intersection terms : ', FL.R2OOS(y_true, Y_pred_elastic))\n",
        "print('R2OOS, generalized linear - without intersection terms / with knots : ', FL.R2OOS(y_true, Y_pred_general_lin))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2OOS, Huber Loss - Linear regression without intersection terms :  -0.0006206035614013672\n",
            "R2OOS, Principal Components Regression - without intersection terms :  -0.015273094177246094\n",
            "R2OOS, Partial Least Square - without intersection terms :  -1.157390536072052\n",
            "R2OOS, Elastic-net - without intersection terms :  0.0024675253993113877\n",
            "R2OOS, generalized linear - without intersection terms / with knots :  0.001908131940232649\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}